<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.262">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CJL Lab - Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">CJL Lab</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-courses" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Courses</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-courses">    
        <li>
    <a class="dropdown-item" href="../../../../teaching/index.html">
 <span class="dropdown-text">All Courses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/ds101/index.html">
 <span class="dropdown-text">Data Science 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/ml101/index.html">
 <span class="dropdown-text">Machine Learning 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/media_ds/index.html">
 <span class="dropdown-text">Media &amp; Data Science</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/cul_tech/index.html">
 <span class="dropdown-text">Culture &amp; Technology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/data_journalism/index.html">
 <span class="dropdown-text">Data Journalism</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-research" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Research</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-research">    
        <li>
    <a class="dropdown-item" href="../../../../research/index.html">
 <span class="dropdown-text">Publications</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../research/working.html">
 <span class="dropdown-text">Work in progress</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../../proj/index.html">
 <span class="menu-text">Proj</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blogs/index.html">
 <span class="menu-text">Blogs</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#pre-class-video" id="toc-pre-class-video" class="nav-link active" data-scroll-target="#pre-class-video">Pre-class video</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#class" id="toc-class" class="nav-link" data-scroll-target="#class">Class</a></li>
  <li><a href="#model-comparison-with-tidymodels-in-r" id="toc-model-comparison-with-tidymodels-in-r" class="nav-link" data-scroll-target="#model-comparison-with-tidymodels-in-r"><strong>Model Comparison with tidymodels in R</strong></a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Classification</h1>
<p class="subtitle lead">K-Nearest Neighbors</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><a href="https://changjunlee.com/teaching/ml101/weekly/">Weekly design</a></p>
<p><br></p>
<section id="pre-class-video" class="level3">
<h3 class="anchored" data-anchor-id="pre-class-video">Pre-class video</h3>
<ul>
<li>Eng ver.</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/nqsDjz9J3SM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>Kor ver.</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/hW7mfp8rwQI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>Pre-class PPT <a href="content/ML_pre_06.pdf">pdf</a></li>
</ul>
<hr>
</section>
<section id="discussion" class="level3">
<h3 class="anchored" data-anchor-id="discussion">Discussion</h3>
<p>Discussion #5</p>
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSfKih4BTRim28ac6EssMaVwIDsKc3k6I7-NPmxqRGRFUNeVEw/viewform?embedded=true" width="640" height="2100" frameborder="0" marginheight="0" marginwidth="0">
<p>Loading…</p>
</iframe>
<hr>
</section>
<section id="class" class="level3">
<h3 class="anchored" data-anchor-id="class">Class</h3>
<section id="introduction" class="level4">
<h4 class="anchored" data-anchor-id="introduction"><strong>Introduction</strong></h4>
<p><strong>Overview of k-nearest neighbor algorithm</strong></p>
<p>The k-nearest neighbor algorithm is a <strong><em>non-parametric algorithm</em></strong> that works <u>by finding the k closest data points in the training set to a new, unseen data point</u>, and then <u>predicting the class or value of that data point based on the labels of its k-nearest neighbors</u>. The algorithm is simple to implement and has a wide range of applications, including image recognition, text classification, and recommendation systems.</p>
<p>For example, let’s say you want to predict whether a new flower is a setosa, versicolor, or virginica based on its sepal length and width. You can use the k-nearest neighbor algorithm to find the k closest flowers in the training set to the new flower, and then predict the most common species among those k flowers.</p>
<p><br></p>
<p><strong>Applications of k-nearest neighbor algorithm</strong></p>
<p>The k-nearest neighbor algorithm has a wide range of applications, including:</p>
<ul>
<li><p><strong>Image recognition</strong>: identifying the content of an image based on its features</p></li>
<li><p><strong>Text classification</strong>: categorizing text documents based on their content</p></li>
<li><p><strong>Recommendation systems</strong>: suggesting products or services based on the preferences of similar users</p></li>
<li><p><strong>Bioinformatics</strong>: identifying similar genes or proteins based on their expression patterns</p></li>
<li><p><strong>Anomaly detection</strong>: identifying unusual data points based on their distance from other data points</p></li>
</ul>
<p><br></p>
<p><strong>Advantages and disadvantages of k-nearest neighbor algorithm</strong></p>
<p>The k-nearest neighbor algorithm has several advantages, including:</p>
<ul>
<li><p>Intuitive and easy to understand</p></li>
<li><p>No assumption about the distribution of the data</p></li>
<li><p>Non-parametric: can work with any type of data</p></li>
<li><p>Can handle multi-class classification problems</p></li>
</ul>
<p>However, the k-nearest neighbor algorithm also has some disadvantages, including:</p>
<ul>
<li><p>Can be computationally expensive for large data sets</p></li>
<li><p>Sensitive to irrelevant features and noisy data</p></li>
<li><p>Requires a good distance metric for accurate predictions</p></li>
<li><p>Choosing the right value of k can be challenging</p></li>
</ul>
<p>Despite these limitations, the k-nearest neighbor algorithm remains a popular and effective machine learning algorithm that is widely used in various fields.</p>
<hr>
</section>
<section id="theory" class="level4">
<h4 class="anchored" data-anchor-id="theory"><strong>Theory</strong></h4>
<p>Let’s dive deeper into the theory behind the k-nearest neighbor algorithm and explore different distance metrics used in the algorithm.</p>
<p><strong>Distance metrics: Euclidean distance, Manhattan distance, etc.</strong></p>
<p>One of the key components of the k-nearest neighbor algorithm is the <em>distance metric</em> used to <u>measure the similarity between two data points</u>. The most commonly used distance metrics are:</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vAtQZbROuTdp36aQQ8cqBA.png" class="img-fluid"></p>
<p>Find out more (<a href="https://tuhinmukherjee74.medium.com/different-types-of-distances-used-in-machine-learning-explained-550e2979752c">here</a>)</p>
<ul>
<li><p><code>Euclidean distance</code>: this is the straight-line distance between two points in Euclidean space. The formula for Euclidean distance between two points, x and y, is:</p>
<p><span class="math display">\[
d(x,y) = \sqrt {\sum(x_i - y_i)^2}
\]</span></p>
<p><strong><code>d(x, y) = sqrt(sum((xi - yi)^2))</code></strong></p></li>
<li><p><code>Manhattan distance</code>: this is the distance between two points measured along the axes at right angles. The formula for Manhattan distance between two points, x and y, is:</p>
<p><span class="math display">\[
d(x,y) = \sum|x_i - y_i|
\]</span></p>
<p><strong><code>d(x, y) = sum(|xi - yi|)</code></strong></p></li>
<li><p><code>Minkowski distance</code>: this is a generalization of Euclidean and Manhattan distance that allows us to control the “shape” of the distance metric. The formula for Minkowski distance between two points, x and y, is:</p>
<p><span class="math display">\[
d(x,y) = (\sum|x_i - y_i|^p)^\frac{1}{p}
\]</span></p>
<p><strong><code>d(x, y) = (sum(|xi - yi|^p))^(1/p)</code></strong></p>
<p>where p is a parameter that controls the “shape” of the distance metric. When p=1, the Minkowski distance is equivalent to Manhattan distance, and when p=2, the Minkowski distance is equivalent to Euclidean distance.</p></li>
</ul>
<p>Choosing the right distance metric is important for accurate predictions in the k-nearest neighbor algorithm. You should choose a distance metric that is appropriate for your data and the problem you are trying to solve.</p>
<p><br></p>
<p><strong>Choosing the value of k</strong></p>
<p>Another important component of the k-nearest neighbor algorithm is the value of <strong><em>k</em></strong>, which represents the number of nearest neighbors used to make the prediction. Choosing the right value of k is crucial for the performance of the algorithm.</p>
<blockquote class="blockquote">
<p>If k is too small, the algorithm may be too sensitive to noise and outliers in the data, leading to overfitting. On the other hand, if k is too large, the algorithm may be too general and fail to capture the nuances of the data, leading to underfitting.</p>
</blockquote>
<p>One common approach to choosing the value of k is to use cross-validation to evaluate the performance of the algorithm on different values of k and choose the value that gives the best performance.</p>
<p><br></p>
<p><strong>Weighted versus unweighted k-nearest neighbor algorithm</strong></p>
<p>In the basic k-nearest neighbor algorithm, all k nearest neighbors are treated equally when making the prediction. However, in some cases, it may be more appropriate to assign different weights to the nearest neighbors based on their distance from the new data point.</p>
<p>For example, you may want to give more weight to the nearest neighbors that are closer to the new data point and less weight to the neighbors that are farther away. This can be done by using a weighted k-nearest neighbor algorithm, where the weights are inversely proportional to the distance between the neighbors and the new data point.</p>
<p><br></p>
<p><strong>Handling ties in k-nearest neighbor algorithm</strong></p>
<p>In some cases, there may be a tie in the labels of the k nearest neighbors, making it difficult to make a prediction. For example, if k=4 and two neighbors are labeled as class A and also two neighbors are labeled as class B, there is a tie between class A and class B.</p>
<p>There are several ways to handle ties in the k-nearest neighbor algorithm. One common approach is to assign the new data point to the class that has the nearest neighbor among the tied classes.</p>
<hr>
</section>
<section id="implementation" class="level4">
<h4 class="anchored" data-anchor-id="implementation"><strong>Implementation</strong></h4>
<p>We introduced the k-nearest neighbor algorithm and discussed its theory, including distance metrics, choosing the value of k, weighted versus unweighted k-nearest neighbor algorithm, and handling ties in k-nearest neighbor algorithm. Let’s learn how to implement the k-nearest neighbor algorithm in R, step by step.</p>
<p><br></p>
<p><strong>Loading data into R</strong></p>
<p>The first step in implementing the k-nearest neighbor algorithm is to load the data into R. In this example, we’ll use the <strong><code>iris</code></strong> dataset, which contains measurements of iris flowers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Splitting data into training and testing sets</strong></p>
<p>The next step is to split the data into training and testing sets. We’ll use 70% of the data for training and 30% of the data for testing.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>train_index <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(iris), <span class="fl">0.7</span> <span class="sc">*</span> <span class="fu">nrow</span>(iris))</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> iris[train_index, ]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> iris[<span class="sc">-</span>train_index, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Preprocessing data: scaling and centering</strong></p>
<p>Before applying the k-nearest neighbor algorithm, it’s important to preprocess the data by scaling and centering the features. We’ll use the <strong><code>scale</code></strong> function in R to scale and center the data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>train_data_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(train_data[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>test_data_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(test_data[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(train_data_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Sepal.Length Sepal.Width Petal.Length Petal.Width
14   -1.76664631  -0.1186139   -1.4793538  -1.4471163
50   -0.96560680   0.5607204   -1.3126884  -1.3157877
118   2.12411700   1.6929443    1.6317336   1.3107847
43   -1.65221209   0.3342756   -1.3682435  -1.3157877
150   0.06430113  -0.1186139    0.7428515   0.7854702
148   0.75090642  -0.1186139    0.7984066   1.0481275</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(train_data_scaled)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Sepal.Length       Sepal.Width       Petal.Length      Petal.Width     
 Min.   :-1.76665   Min.   :-1.9302   Min.   :-1.5349   Min.   :-1.4471  
 1st Qu.:-0.85117   1st Qu.:-0.5715   1st Qu.:-1.2016   1st Qu.:-1.1845  
 Median :-0.05013   Median :-0.1186   Median : 0.3540   Median : 0.2602  
 Mean   : 0.00000   Mean   : 0.0000   Mean   : 0.0000   Mean   : 0.0000  
 3rd Qu.: 0.63647   3rd Qu.: 0.7872   3rd Qu.: 0.7429   3rd Qu.: 0.7855  
 Max.   : 2.35299   Max.   : 3.0516   Max.   : 1.7428   Max.   : 1.7048  </code></pre>
</div>
</div>
<p>When working with machine learning algorithms, especially <em>distance-based methods</em> such as k-nearest neighbors (kNN), <u>it is crucial to preprocess the data by scaling and centering the features</u>. This ensures that all features contribute equally to the model’s performance and prevents features with larger magnitudes from dominating the algorithm.</p>
<p><br></p>
<p><strong>Scaling</strong> and centering involve transforming the data such that the features have a mean of 0 and a standard deviation of 1. The transformation is performed using the following equations:</p>
<ol type="1">
<li><p>Centering (Mean subtraction):</p>
<p><strong><code>X_centered = X - mean(X)</code></strong></p>
<p>This step involves subtracting the mean of the feature from each data point, effectively centering the data around 0.</p></li>
<li><p>Scaling (Divide by standard deviation):</p>
<p><strong><code>X_scaled = X_centered / sd(X)</code></strong></p>
<p>In this step, we divide the centered data by the standard deviation, resulting in a transformed feature with a standard deviation of 1.</p></li>
</ol>
<p>In R, we can use the <strong><code>scale()</code></strong> function to perform both centering and scaling in one step. Here’s how to apply it to the train_data and test_data.</p>
<p><br></p>
<p><strong>Min-max normalization</strong> is another preprocessing technique used to scale the features within a specific range, usually [0, 1]. This method can be particularly useful when working with algorithms sensitive to feature magnitudes or when we want to maintain the same unit of measurement across features.</p>
<p>Min-max normalization is performed using the following equation:</p>
<p><strong><code>X_normalized = (X - min(X)) / (max(X) - min(X))</code></strong></p>
<p>This transformation scales the data linearly between the minimum and maximum values of each feature.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the min-max normalization function</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>min_max_normalize <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  (x <span class="sc">-</span> <span class="fu">min</span>(x)) <span class="sc">/</span> (<span class="fu">max</span>(x) <span class="sc">-</span> <span class="fu">min</span>(x))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>train_data_normalized <span class="ot">&lt;-</span> <span class="fu">min_max_normalize</span>(train_data[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(train_data_normalized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Sepal.Length Sepal.Width Petal.Length Petal.Width
14     0.5384615   0.3717949    0.1282051  0.00000000
50     0.6282051   0.4102564    0.1666667  0.01282051
118    0.9743590   0.4743590    0.8461538  0.26923077
43     0.5512821   0.3974359    0.1538462  0.01282051
150    0.7435897   0.3717949    0.6410256  0.21794872
148    0.8205128   0.3717949    0.6538462  0.24358974</code></pre>
</div>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(train_data_normalized)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Sepal.Length     Sepal.Width      Petal.Length     Petal.Width     
 Min.   :0.5385   Min.   :0.2692   Min.   :0.1154   Min.   :0.00000  
 1st Qu.:0.6410   1st Qu.:0.3462   1st Qu.:0.1923   1st Qu.:0.02564  
 Median :0.7308   Median :0.3718   Median :0.5513   Median :0.16667  
 Mean   :0.7364   Mean   :0.3785   Mean   :0.4696   Mean   :0.14127  
 3rd Qu.:0.8077   3rd Qu.:0.4231   3rd Qu.:0.6410   3rd Qu.:0.21795  
 Max.   :1.0000   Max.   :0.5513   Max.   :0.8718   Max.   :0.30769  </code></pre>
</div>
</div>
<p><strong>Writing a function to calculate distances</strong></p>
<p>Next, we’ll write a function to calculate distances between two data points using the Euclidean distance metric.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>euclidean_distance <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(<span class="fu">sum</span>((x <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Implementing k-nearest neighbor algorithm using class package</strong></p>
<p>We’ll use the <strong><code>class</code></strong> package in R to implement the k-nearest neighbor algorithm. We’ll use the <strong><code>knn</code></strong> function in the <strong><code>class</code></strong> package to make predictions based on the k nearest neighbors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(class)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>predicted_classes <span class="ot">&lt;-</span> <span class="fu">knn</span>(<span class="at">train =</span> train_data_scaled, </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>                         <span class="at">test =</span> test_data_scaled, </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>                         <span class="at">cl =</span> train_data[, <span class="dv">5</span>], </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>                         <span class="at">k =</span> k, </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>                         <span class="at">prob =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>In the code above, we set <strong><code>k</code></strong> to 5, which means we’ll use the 5 nearest neighbors to make the prediction. The <strong><code>knn</code></strong> function returns the predicted classes of the test data, based on the labels of the nearest neighbors in the training data. The option <code>cl</code> means class, <code>prop</code> means that the result comes with the probability.</p>
<p><br></p>
<p><strong>Evaluating model performance using confusion matrix, accuracy, precision, recall, and F1-score</strong></p>
<p>Finally, we’ll evaluate the performance of the k-nearest neighbor algorithm using a confusion matrix, accuracy, precision, recall, and F1-score.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: ggplot2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: lattice</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(predicted_classes, test_data[, <span class="dv">5</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix and Statistics

            Reference
Prediction   setosa versicolor virginica
  setosa         14          0         0
  versicolor      0         17         0
  virginica       0          1        13

Overall Statistics
                                          
               Accuracy : 0.9778          
                 95% CI : (0.8823, 0.9994)
    No Information Rate : 0.4             
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.9664          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: setosa Class: versicolor Class: virginica
Sensitivity                 1.0000            0.9444           1.0000
Specificity                 1.0000            1.0000           0.9688
Pos Pred Value              1.0000            1.0000           0.9286
Neg Pred Value              1.0000            0.9643           1.0000
Prevalence                  0.3111            0.4000           0.2889
Detection Rate              0.3111            0.3778           0.2889
Detection Prevalence        0.3111            0.3778           0.3111
Balanced Accuracy           1.0000            0.9722           0.9844</code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix<span class="sc">$</span>byClass[,<span class="st">"Precision"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Class: setosa Class: versicolor  Class: virginica 
        1.0000000         1.0000000         0.9285714 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix<span class="sc">$</span>byClass[,<span class="st">"Recall"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Class: setosa Class: versicolor  Class: virginica 
        1.0000000         0.9444444         1.0000000 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>confusion_matrix<span class="sc">$</span>byClass[,<span class="st">"F1"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    Class: setosa Class: versicolor  Class: virginica 
        1.0000000         0.9714286         0.9629630 </code></pre>
</div>
</div>
<p>In the code above, we use the <strong><code>confusionMatrix</code></strong> function in the <strong><code>caret</code></strong> package to generate a confusion matrix based on the predicted classes and the true labels of the test data. We then extract the overall accuracy and the precision, recall, and F1-score for each class from the confusion matrix.</p>
<p><br></p>
<p><strong>What is F1 score?</strong></p>
<p><code>F1 score</code> is a measure of a machine learning algorithm’s accuracy that combines precision and recall. It is the <strong>harmonic mean of precision and recall</strong>, and ranges from 0 to 1, with higher values indicating better performance.</p>
<p>F1 score is calculated using the following formula:</p>
<p><span class="math display">\[
F1 = 2 \times \frac{Precision \times Recall}{Precesion + Recall}
\]</span></p>
<p><code>F1 score = 2 * (precision * recall) / (precision + recall)</code></p>
<p>where <strong><code>precision</code></strong> is the number of true positives divided by the total number of positive predictions, and <strong><code>recall</code></strong> is the number of true positives divided by the total number of actual positives.</p>
<p><strong>Why use F1 score?</strong></p>
<p>F1 score is useful when the dataset is imbalanced, meaning that the number of positive and negative examples is not equal. In such cases, accuracy alone is not a good measure of the algorithm’s performance, as a high accuracy can be achieved by simply predicting the majority class all the time.</p>
<p>Instead, we need a metric that takes into account both precision and recall, as precision measures the algorithm’s ability to make correct positive predictions, and recall measures the algorithm’s ability to find all positive examples in the dataset.</p>
<p><strong>How to interpret F1 score?</strong></p>
<p>F1 score ranges from 0 to 1, with higher values indicating better performance. An F1 score of 1 means perfect precision and recall, while an F1 score of 0 means that either the precision or recall is 0.</p>
<p>In practice, we aim to achieve a high F1 score while balancing precision and recall based on the problem and its requirements. For example, in medical diagnosis, we may want to prioritize recall over precision to avoid missing any positive cases, while in fraud detection, we may want to prioritize precision over recall to avoid false positives.</p>
<hr>
</section>
<section id="qzs" class="level4">
<h4 class="anchored" data-anchor-id="qzs"><strong>QZs</strong></h4>
<ol type="1">
<li>Which of the following is a distance metric commonly used in the k-nearest neighbor algorithm?
<ol type="a">
<li>Correlation distance</li>
<li>Chebyshev distance</li>
<li>Hamming distance</li>
<li>All of the above</li>
</ol></li>
<li>How do you choose the value of k in the k-nearest neighbor algorithm?
<ol type="a">
<li>Choose a small value of k to avoid overfitting</li>
<li>Choose a large value of k to avoid overfitting</li>
<li>Use cross-validation to evaluate the performance of the algorithm on different values of k and choose the value that gives the best performance</li>
<li>None of the above</li>
</ol></li>
<li>What is the difference between weighted and unweighted k-nearest neighbor algorithm?
<ol type="a">
<li>Weighted k-nearest neighbor algorithm gives more weight to the nearest neighbors that are farther away</li>
<li>Unweighted k-nearest neighbor algorithm gives more weight to the nearest neighbors that are closer</li>
<li>Weighted k-nearest neighbor algorithm assigns different weights to the nearest neighbors based on their distance from the new data point</li>
<li>Unweighted k-nearest neighbor algorithm assigns different weights to the nearest neighbors based on their distance from the new data point</li>
</ol></li>
<li>What is F1 score?
<ol type="a">
<li>A measure of a machine learning algorithm’s accuracy that combines precision and recall</li>
<li>The average of precision and recall</li>
<li>The harmonic mean of precision and recall</li>
<li>None of the above</li>
</ol></li>
<li>What is the formula for calculating Euclidean distance between two points in Euclidean space?
<ol type="a">
<li>d(x, y) = sqrt(sum((xi - yi)^2))</li>
<li>d(x, y) = sum(|xi - yi|)</li>
<li>d(x, y) = (sum(|xi - yi|^p))^(1/p)</li>
<li>None of the above</li>
</ol></li>
<li>What is the purpose of scaling and centering the features in the k-nearest neighbor algorithm?
<ol type="a">
<li>To make the features easier to interpret</li>
<li>To make the features more accurate</li>
<li>To make the features more comparable</li>
<li>None of the above</li>
</ol></li>
<li>How can you handle ties in the k-nearest neighbor algorithm?
<ol type="a">
<li>Assign the new data point to the class that has the nearest neighbor among the tied classes</li>
<li>Assign the new data point to the class that has the farthest neighbor among the tied classes</li>
<li>Assign the new data point to the class that has the most neighbors among the tied classes</li>
<li>None of the above</li>
</ol></li>
</ol>
<p>Ans) dcccaca</p>
<hr>
<p>In this week, we learned about the k-nearest neighbor algorithm, a popular machine learning algorithm used for classification and regression problems. We started with an overview of the algorithm and its applications, and discussed the advantages and disadvantages of the algorithm.</p>
<p>We then delved into the theory behind the k-nearest neighbor algorithm, including distance metrics such as Euclidean distance and Manhattan distance, choosing the value of k, weighted versus unweighted k-nearest neighbor algorithm, and handling ties in k-nearest neighbor algorithm.</p>
<p>We also showed you how to implement the k-nearest neighbor algorithm in R step by step, including loading data into R, splitting data into training and testing sets, preprocessing data, writing a function to calculate distances, and evaluating model performance using confusion matrix, accuracy, precision, recall, and F1-score.</p>
<p>Finally, we gave you the opportunity to practice implementing the k-nearest neighbor algorithm on your own data set and evaluate the model’s performance.</p>
<p>By understanding the k-nearest neighbor algorithm and its theory, as well as its implementation in R, you can apply this algorithm to your own machine learning problems and make informed decisions about your data. Keep practicing and exploring different machine learning algorithms to expand your knowledge and skills in data science.</p>
<hr>
<p><br></p>
</section>
</section>
<section id="model-comparison-with-tidymodels-in-r" class="level3">
<h3 class="anchored" data-anchor-id="model-comparison-with-tidymodels-in-r"><strong>Model Comparison with tidymodels in R</strong></h3>
<p>Let’s learn how to compare four different machine learning models using the <a href="https://www.tidymodels.org/"><code>tidymodels</code></a> package in R. We will be using the classic <code>Iris</code> dataset to showcase this comparison. The models we will compare are Decision Trees, Random Forests, Naive Bayes, and k-Nearest Neighbors (kNN).</p>
<p><br> First, let’s load the necessary libraries and the Iris dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the required libraries</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>✔ broom        1.0.4     ✔ rsample      1.1.1
✔ dials        1.1.0     ✔ tibble       3.1.8
✔ dplyr        1.1.0     ✔ tidyr        1.3.0
✔ infer        1.0.4     ✔ tune         1.0.1
✔ modeldata    1.0.1     ✔ workflows    1.1.2
✔ parsnip      1.0.3     ✔ workflowsets 1.0.0
✔ purrr        1.0.1     ✔ yardstick    1.1.0
✔ recipes      1.0.4     </code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard()         masks scales::discard()
✖ dplyr::filter()          masks stats::filter()
✖ dplyr::lag()             masks stats::lag()
✖ purrr::lift()            masks caret::lift()
✖ yardstick::precision()   masks caret::precision()
✖ yardstick::recall()      masks caret::recall()
✖ yardstick::sensitivity() masks caret::sensitivity()
✖ yardstick::specificity() masks caret::specificity()
✖ recipes::step()          masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ forcats   1.0.0     ✔ readr     2.1.4
✔ lubridate 1.9.2     ✔ stringr   1.5.0</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ readr::col_factor() masks scales::col_factor()
✖ purrr::discard()    masks scales::discard()
✖ dplyr::filter()     masks stats::filter()
✖ stringr::fixed()    masks recipes::fixed()
✖ dplyr::lag()        masks stats::lag()
✖ purrr::lift()       masks caret::lift()
✖ readr::spec()       masks yardstick::spec()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'rpart'

The following object is masked from 'package:dials':

    prune</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(discrim)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'discrim' was built under R version 4.2.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'discrim'

The following object is masked from 'package:dials':

    smoothness</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(naivebayes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'naivebayes' was built under R version 4.2.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>naivebayes 0.9.7 loaded</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kknn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'kknn' was built under R version 4.2.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'kknn'

The following object is masked from 'package:caret':

    contr.dummy</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(yardstick)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Iris dataset</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Before we begin modeling, we need to <strong>preprocess the data</strong>. We will split the dataset into training (75%) and testing (25%) sets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>data_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(iris, <span class="at">prop =</span> <span class="fl">0.75</span>)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">training</span>(data_split)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">testing</span>(data_split)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, we will <strong>create the models</strong> using tidymodels’ <strong><code>parsnip</code></strong> package. Each model will be created using a similar structure, specifying the model type and the mode (classification in this case).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>decision_tree <span class="ot">&lt;-</span> <span class="fu">decision_tree</span>() <span class="sc">%&gt;%</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"rpart"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>random_forest <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>() <span class="sc">%&gt;%</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"randomForest"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive Bayes</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>naive_bayes <span class="ot">&lt;-</span> <span class="fu">naive_Bayes</span>() <span class="sc">%&gt;%</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"naivebayes"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="co"># k-Nearest Neighbors (kNN)</span></span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>knn <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>() <span class="sc">%&gt;%</span></span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">"kknn"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">"classification"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>Next, we will <strong>create a workflow</strong> for each model. In this example, we don’t require any preprocessing steps, so we will directly specify the model in the workflow.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision Tree Workflow</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>workflow_dt <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(decision_tree) <span class="sc">%&gt;%</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(Species <span class="sc">~</span> .)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest Workflow</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>workflow_rf <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(random_forest) <span class="sc">%&gt;%</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(Species <span class="sc">~</span> .)</span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Naive Bayes Workflow</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a>workflow_nb <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(naive_bayes) <span class="sc">%&gt;%</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(Species <span class="sc">~</span> .)</span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># kNN Workflow</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>workflow_knn <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(knn) <span class="sc">%&gt;%</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_formula</span>(Species <span class="sc">~</span> .)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>We will now <strong>fit each model</strong> using the training data and make predictions on the test data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>fit_dt <span class="ot">&lt;-</span> <span class="fu">fit</span>(workflow_dt, <span class="at">data =</span> train_data)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>fit_rf <span class="ot">&lt;-</span> <span class="fu">fit</span>(workflow_rf, <span class="at">data =</span> train_data)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>fit_nb <span class="ot">&lt;-</span> <span class="fu">fit</span>(workflow_nb, <span class="at">data =</span> train_data)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>fit_knn <span class="ot">&lt;-</span> <span class="fu">fit</span>(workflow_knn, <span class="at">data =</span> train_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>Finally, we will evaluate the performance of each model using accuracy as the metric.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit_dt, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_dt, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add the true outcome data back in</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 38 × 5
   .pred_class .pred_setosa .pred_versicolor .pred_virginica Species
   &lt;fct&gt;              &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt; &lt;fct&gt;  
 1 setosa                 1                0               0 setosa 
 2 setosa                 1                0               0 setosa 
 3 setosa                 1                0               0 setosa 
 4 setosa                 1                0               0 setosa 
 5 setosa                 1                0               0 setosa 
 6 setosa                 1                0               0 setosa 
 7 setosa                 1                0               0 setosa 
 8 setosa                 1                0               0 setosa 
 9 setosa                 1                0               0 setosa 
10 setosa                 1                0               0 setosa 
# ℹ 28 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(fit_dt, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_dt, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species)) <span class="sc">%&gt;%</span> </span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add accuracy function from yardstick</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Species, .pred_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 3
  .metric  .estimator .estimate
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
1 accuracy multiclass     0.947</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All together </span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>accuracy_dt <span class="ot">&lt;-</span> </span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(fit_dt, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_dt, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species)) <span class="sc">%&gt;%</span> </span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Species, .pred_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Do the same things for the other models</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>accuracy_rf <span class="ot">&lt;-</span> </span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(fit_rf, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_rf, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Species, .pred_class)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>accuracy_nb <span class="ot">&lt;-</span> </span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(fit_nb, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_nb, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Species, .pred_class)</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>accuracy_knn <span class="ot">&lt;-</span> </span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(fit_knn, test_data) <span class="sc">%&gt;%</span> </span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(fit_knn, test_data, <span class="at">type =</span> <span class="st">"prob"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(test_data <span class="sc">%&gt;%</span> </span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a>              <span class="fu">select</span>(Species)) <span class="sc">%&gt;%</span> </span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">accuracy</span>(<span class="at">truth =</span> Species, .pred_class)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>calculates the accuracy for each model and displays the results in a sorted data frame.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>accuracy_dt <span class="sc">%&gt;%</span> </span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(accuracy_rf, accuracy_nb, accuracy_knn) <span class="sc">%&gt;%</span> </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">models =</span> <span class="fu">c</span>(<span class="st">"Decision Tree"</span>, <span class="st">"Random Forest"</span>, <span class="st">"Naive Bayes"</span>, <span class="st">"kNN"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(.estimate))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 4 × 4
  .metric  .estimator .estimate models       
  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;        
1 accuracy multiclass     0.974 kNN          
2 accuracy multiclass     0.947 Decision Tree
3 accuracy multiclass     0.947 Random Forest
4 accuracy multiclass     0.947 Naive Bayes  </code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ChangjunChrisLee/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Dr_CJLee">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:changjun.chris.lee@gmail.com">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



</body></html>