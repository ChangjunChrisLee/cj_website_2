<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Regression – CJL &amp; Lab</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">CJL &amp; Lab</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-courses" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Courses</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-courses">    
        <li>
    <a class="dropdown-item" href="../../../../teaching/index.html">
 <span class="dropdown-text">All Courses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/ds101/index.html">
 <span class="dropdown-text">DS101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../../../teaching/grad_immersive/index.html">
 <span class="dropdown-text">IMUX</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../../../research/index.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../proj/index.html"> 
<span class="menu-text">Proj</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blogs/index.html"> 
<span class="menu-text">Blogs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://axislab.netlify.app/"> 
<span class="menu-text">LAB</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#pre-class-video" id="toc-pre-class-video" class="nav-link active" data-scroll-target="#pre-class-video">Pre-class video</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a></li>
  <li><a href="#class" id="toc-class" class="nav-link" data-scroll-target="#class">Class</a>
  <ul class="collapse">
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation">Motivation</a></li>
  <li><a href="#usage-and-importance" id="toc-usage-and-importance" class="nav-link" data-scroll-target="#usage-and-importance">Usage and Importance</a></li>
  <li><a href="#real-world-applications" id="toc-real-world-applications" class="nav-link" data-scroll-target="#real-world-applications">Real-world Applications</a></li>
  <li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory">Theory</a></li>
  <li><a href="#pop-up-quizzes" id="toc-pop-up-quizzes" class="nav-link" data-scroll-target="#pop-up-quizzes">Pop-up Quizzes</a></li>
  <li><a href="#hands-on-practice" id="toc-hands-on-practice" class="nav-link" data-scroll-target="#hands-on-practice">Hands-on Practice</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#for-your-further-study" id="toc-for-your-further-study" class="nav-link" data-scroll-target="#for-your-further-study">For your further study</a>
  <ul class="collapse">
  <li><a href="#derivation-of-the-coefficient-least-squares-ls-method" id="toc-derivation-of-the-coefficient-least-squares-ls-method" class="nav-link" data-scroll-target="#derivation-of-the-coefficient-least-squares-ls-method">Derivation of the Coefficient: Least Squares (LS) Method</a></li>
  <li><a href="#steps-to-estimate-the-standard-error-textsehatbeta" id="toc-steps-to-estimate-the-standard-error-textsehatbeta" class="nav-link" data-scroll-target="#steps-to-estimate-the-standard-error-textsehatbeta">Steps to Estimate the Standard Error <span class="math inline">\(\text{SE}(\hat{\beta})\)</span></a></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Regression</h1>
<p class="subtitle lead">Linear Regression</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://changjunlee.com/teaching/ml101/weekly/">Weekly design</a></p>
<p><br></p>
<section id="pre-class-video" class="level2">
<h2 class="anchored" data-anchor-id="pre-class-video">Pre-class video</h2>
<ul>
<li>Eng ver.</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gdljZKTE-_Q" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>Kor ver.</li>
</ul>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/WEJwpmsRwYY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li>Pre-class PPT <a href="content/ML_pre_07.pdf">pdf</a></li>
</ul>
<hr>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>Discussion #6</p>
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdHdIImmEyQ7mMLzWvL1O4VsWZjcYwSdPPGXrnm4C2XybyKAw/viewform?embedded=true" width="640" height="3600" frameborder="0" marginheight="0" marginwidth="0">
<p>Loading…</p>
</iframe>
<hr>
</section>
<section id="class" class="level2">
<h2 class="anchored" data-anchor-id="class">Class</h2>
<p><br></p>
<section id="motivation" class="level3">
<h3 class="anchored" data-anchor-id="motivation">Motivation</h3>
<p><strong>Linear regression</strong> is a foundational technique in statistical analysis and machine learning that helps us understand and <strong>quantify relationships between variables</strong>. As social scientists, we often aim to analyze the effect of certain factors on an outcome of interest. Linear regression provides us with a way to model these relationships, quantify their effects, and make predictions based on our findings. By mastering linear regression, social scientists can gain valuable insights into various phenomena, test hypotheses, and make data-driven decisions.</p>
<p><br></p>
</section>
<section id="usage-and-importance" class="level3">
<h3 class="anchored" data-anchor-id="usage-and-importance">Usage and Importance</h3>
<p>Linear regression is widely used in social science research for several reasons:</p>
<ul>
<li><p><strong>Simplicity</strong>: Linear regression is relatively easy to understand and implement, making it an accessible method for researchers across disciplines. Despite its simplicity, it can often provide valuable insights and predictions.</p></li>
<li><p><strong>Interpretability</strong>: The coefficients obtained from linear regression have a clear interpretation, allowing researchers to understand the effect of each independent variable on the dependent variable.</p></li>
<li><p><strong>Basis for Advanced Techniques</strong>: Linear regression serves as a foundation for more advanced statistical and machine learning techniques. Gaining a deep understanding of linear regression helps social scientists better understand and apply these more advanced methods.</p></li>
</ul>
</section>
<section id="real-world-applications" class="level3">
<h3 class="anchored" data-anchor-id="real-world-applications">Real-world Applications</h3>
<p>Linear regression has a wide range of applications in social science research. Some examples include:</p>
<ul>
<li><p><strong>Economics</strong>: Linear regression can be used to study the impact of various factors on economic indicators, such as GDP growth, unemployment rate, and inflation.</p></li>
<li><p><strong>Political Science</strong>: Researchers can use linear regression to analyze the effects of political factors on election outcomes, public opinion, or policy decisions.</p></li>
<li><p><strong>Sociology</strong>: Linear regression can help us understand the relationship between social variables, such as education level, income, and various social outcomes like crime rates, health status, and life satisfaction.</p></li>
<li><p><strong>Psychology</strong>: Researchers can use linear regression to study the effects of different psychological factors on human behavior, mental health, and well-being.</p></li>
<li><p><strong>Education</strong>: Linear regression can be used to analyze the impact of various factors on educational outcomes, such as standardized test scores, graduation rates, and college enrollment.</p></li>
</ul>
<p>Overall, linear regression is a versatile and powerful tool for social scientists, enabling them to gain insights into the relationships between variables and make evidence-based predictions.</p>
<hr>
</section>
<section id="theory" class="level3">
<h3 class="anchored" data-anchor-id="theory">Theory</h3>
<p><strong>Simple Linear Regression</strong></p>
<blockquote class="blockquote">
<p>Simple linear regression is a statistical method that helps us understand the relationship between one dependent variable (y) and one independent variable (x). It models the relationship as a linear function.</p>
</blockquote>
<p><img src="http://cdn-0.r-statistics.co/screenshots/linear-regression-small.png" class="img-fluid"></p>
<p><strong>Equation</strong>:</p>
<p><span class="math display">\[
y = β_1 + β_2x + ε
\]</span></p>
<ul>
<li><p><span class="math inline">\(y\)</span> : dependent variable (outcome)</p></li>
<li><p><span class="math inline">\(x\)</span> : independent variable (predictor)</p></li>
<li><p><span class="math inline">\(β_1\)</span> : intercept (value of y when x = 0)</p></li>
<li><p><span class="math inline">\(β_2\)</span> : slope (change in y for a one-unit increase in x)</p></li>
<li><p><span class="math inline">\(ε\)</span> : error term (difference between the predicted and observed values of y)</p></li>
</ul>
<p><br></p>
<p><strong>Multiple Linear Regression</strong></p>
<blockquote class="blockquote">
<p>Multiple linear regression is an extension of simple linear regression that allows us to model the relationship between one dependent variable (y) and multiple independent variables (x₁, x₂, …, xₙ). It is useful when we want to analyze the impact of several predictors on an outcome variable.</p>
</blockquote>
<p>Equation</p>
<p><span class="math display">\[
y = β₀ + β₁x₁ + β₂x₂ + … + βₙxₙ + ε
\]</span></p>
<ul>
<li><p><span class="math inline">\(y\)</span> : dependent variable (outcome)</p></li>
<li><p><span class="math inline">\(x₁, x₂, …, xₙ\)</span> : independent variables (predictors)</p></li>
<li><p><span class="math inline">\(β₀\)</span> : intercept (value of y when all x’s are 0)</p></li>
<li><p><span class="math inline">\(β₁, β₂, …, βₙ\)</span> : coefficients (change in y for a one-unit increase in the corresponding x)</p></li>
<li><p><span class="math inline">\(ε\)</span> : error term (difference between the predicted and observed values of y)</p></li>
</ul>
<p><br></p>
<p><strong>Assumptions of Linear Regression</strong></p>
<ul>
<li><p><code>Linearity</code>: The relationship between the dependent variable and the independent variables is linear.</p></li>
<li><p><code>Independence</code>: The observations in the dataset are independent of each other.</p></li>
<li><p><code>Homoscedasticity</code>: The variance of the error term is constant for all values of the independent variables.</p></li>
<li><p><code>Normality</code>: The error term follows a normal distribution.</p></li>
<li><p><code>No multicollinearity</code>: The independent variables are not highly correlated with each other.</p></li>
</ul>
<p><br></p>
<p><strong>Coefficient Estimation: Least Squares (LS) Method</strong></p>
<blockquote class="blockquote">
<p>Minimize the sum of the squared differences between the observed and predicted values of the dependent variable.</p>
</blockquote>
<ul>
<li><p>Formula:</p>
<p><span class="math display">\[
β = (X'X)^{-1}X'y
\]</span>where X is the matrix of independent variables, y is the dependent variable, and β is the vector of coefficients.</p></li>
</ul>
<p><strong>Model Evaluation Metrics</strong></p>
<ul>
<li><p>R-squared (Coefficient of Determination): Proportion of the variance in the dependent variable that can be explained by the independent variables. Ranges from 0 to 1.</p>
<p><span class="math display">\[
R^2 = 1- \frac{SSE}{SST}
\]</span></p>
<p><span class="math display">\[
SSE = \sum(y_i - \hat{y_i})^2
\]</span></p>
<p><span class="math display">\[
SST=\sum(y_i - \bar{y_i})^2
\]</span></p>
<blockquote class="blockquote">
<p>where <em>SSE</em> is the sum of squared errors and <em>SST</em> is the sum of squared total</p>
</blockquote></li>
<li><p>Adjusted R-squared: R-squared adjusted for the number of predictors in the model. Useful for comparing models with different numbers of predictors.</p>
<p><span class="math display">\[
Adj.R^2=1-\frac{(1-R^2)(N-1)}{N-p-1}
\]</span></p>
<blockquote class="blockquote">
<p>where <span class="math inline">\(R^2\)</span> is sample R-squared, <span class="math inline">\(N\)</span> is Total Sample Size, and <span class="math inline">\(p\)</span> is the number of independent variables</p>
</blockquote></li>
<li><p>Root Mean Squared Error (RMSE): The square root of the average squared differences between the observed and predicted values of the dependent variable. A measure of the model’s prediction accuracy.</p>
<p><span class="math display">\[
RMSE = \sqrt{\frac{\sum_{i=1}^{N}{(y_i-\hat{y_i})^2}}{N}}
\]</span></p>
<blockquote class="blockquote">
<p>where N is the number of data points (observations)</p>
</blockquote></li>
</ul>
<hr>
</section>
<section id="pop-up-quizzes" class="level3">
<h3 class="anchored" data-anchor-id="pop-up-quizzes">Pop-up Quizzes</h3>
<ol type="1">
<li><p>What is the main objective of simple linear regression?</p>
<ol type="a">
<li>To predict the value of a dependent variable based on the values of multiple independent variables.</li>
<li>To predict the value of a dependent variable based on the value of one independent variable.</li>
<li>To predict the values of independent variables based on the value of a dependent variable.</li>
<li>To find the correlation between two independent variables.</li>
</ol></li>
<li><p>In a multiple linear regression model, what happens when two or more independent variables are highly correlated with each other?</p>
<ol type="a">
<li>The model becomes more accurate.</li>
<li>The model becomes more interpretable.</li>
<li>Multicollinearity occurs, which can affect the stability and interpretation of the coefficients.</li>
<li>The model’s R-squared value decreases significantly.</li>
</ol></li>
<li><p>Which of the following is NOT an assumption of linear regression?</p>
<ol type="a">
<li>Linearity</li>
<li>Independence</li>
<li>Homoscedasticity</li>
<li>Exponential distribution of the error term</li>
</ol></li>
<li><p>In a simple linear regression model with the equation y = β₀ + β₁x + ε, what does β₁ represent?</p>
<ol type="a">
<li>The intercept of the model, or the value of y when x = 0.</li>
<li>The slope of the model, or the change in y for a one-unit increase in x.</li>
<li>The error term, or the difference between the predicted and observed values of y.</li>
<li>The coefficient of determination, or the proportion of the variance in y explained by x.</li>
</ol></li>
<li><p>Which of the following metrics can be used to evaluate the performance of a linear regression model?</p>
<ol type="a">
<li>R-squared</li>
<li>Adjusted R-squared</li>
<li>Root Mean Squared Error (RMSE)</li>
<li>All of the above</li>
</ol>
<p><strong>Answers</strong>: bcdbd</p></li>
</ol>
<hr>
</section>
<section id="hands-on-practice" class="level3">
<h3 class="anchored" data-anchor-id="hands-on-practice">Hands-on Practice</h3>
<p>For this hands-on practice, we will use the <code>mtcars</code> dataset, which is built into R. The dataset contains information about various car models, including miles per gallon (mpg), number of cylinders (cyl), horsepower (hp), and weight (wt). The goal is to predict miles per gallon based on the number of cylinders, horsepower, and weight using linear regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ ggplot2   3.5.1     ✔ tibble    3.2.1
✔ lubridate 1.9.3     ✔ tidyr     1.3.1
✔ purrr     1.0.2     
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the 'mtcars' dataset</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># View the first few rows of the dataset</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mtcars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                   mpg cyl disp  hp drat    wt  qsec vs am gear carb
Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
</div>
</div>
<p><strong>Exploratory Data Analysis</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary statistics</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mtcars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      mpg             cyl             disp             hp       
 Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  
 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  
 Median :19.20   Median :6.000   Median :196.3   Median :123.0  
 Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  
 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  
 Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  
      drat             wt             qsec             vs        
 Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  
 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  
 Median :3.695   Median :3.325   Median :17.71   Median :0.0000  
 Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  
 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  
 Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  
       am              gear            carb      
 Min.   :0.0000   Min.   :3.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  
 Median :0.0000   Median :4.000   Median :2.000  
 Mean   :0.4062   Mean   :3.688   Mean   :2.812  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  
 Max.   :1.0000   Max.   :5.000   Max.   :8.000  </code></pre>
</div>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize relationships between variables using scatterplots</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(mtcars[, <span class="fu">c</span>(<span class="st">"mpg"</span>, <span class="st">"cyl"</span>, <span class="st">"hp"</span>, <span class="st">"wt"</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="07_week_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Simple Linear Regression in R (Predicting mpg based on weight)</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a simple linear regression model</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Model summary and interpretation</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simple_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model diagnostics (residuals vs. fitted values)</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(simple_model, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="07_week_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Hypothesis Testing and Statistical Significance in Linear Regression</strong></p>
<p>T-statistics and p-values are essential concepts in statistical hypothesis testing and linear regression analysis.</p>
<ul>
<li><p>T-statistics</p>
<blockquote class="blockquote">
<p>A t-statistic is a measure of how many standard deviations a regression coefficient is from zero. It is used to test the null hypothesis that there is no relationship between the independent and dependent variables (i.e., the coefficient is zero). A higher t-statistic value indicates a stronger relationship between the variables.</p>
</blockquote>
<p>The t-statistic for a regression coefficient can be calculated as:</p>
<p><span class="math display">\[
t = \frac{\beta - H₀}{se(\beta)}
\]</span></p>
<blockquote class="blockquote">
<p>where <span class="math inline">\(t\)</span> is the t-statistic, <span class="math inline">\(\beta\)</span> is the estimated regression coefficient, <span class="math inline">\(H₀\)</span> is the null hypothesis value (usually 0), and <span class="math inline">\(se(\beta)\)</span> is the standard error of the estimated coefficient.</p>
</blockquote>
<p>See appendix (further study part) if you want to dig in more about the way of estimating <span class="math inline">\(se(\beta)\)</span>.</p></li>
</ul>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>t-통계량</strong>은 <strong>클 수록</strong> 좋음: 분자는 클 수록, 분모는 작을 수록</p></li>
<li><p>분자가 크려면: 회귀 계수 (Beta의 추정값)이 커야함</p></li>
<li><p>분모가 작으려면: 회귀 계수의 표준 오차가 작아야함 (표준 오차 추정법은 부록 참고)</p></li>
<li><p>회귀 계수의 표준 오차가 작으려면: <span class="math inline">\(se(\beta)\)</span> = MSE / (X의 표준편차 * 표본수) 이므로 MSE가 작아야 하고 표본수가 커야함.</p></li>
<li><p><strong>종합하면, 회귀 계수가 크고, MSE가 작고, 표본 수가 커질 수록 t-통계량이 커진다</strong></p></li>
</ul>
</div>
</div>
<p><br></p>
<ul>
<li><p>P-values</p>
<blockquote class="blockquote">
<p>A p-value is the probability of obtaining a test statistic as extreme as the observed value under the null hypothesis. It helps us determine the statistical significance of a regression coefficient. In general, a smaller p-value (typically ≤ 0.05) indicates strong evidence against the null hypothesis, suggesting that the coefficient is significantly different from zero.</p>
</blockquote>
<p>To calculate the p-value for a t-statistic, we use the cumulative distribution function (CDF) of the t-distribution with n - k degrees of freedom, where n is the number of observations and k is the number of estimated coefficients (including the intercept).</p>
<p><span class="math display">\[
P(T &gt; |t|) = 1 - CDF(t, df = n - k)
\]</span></p></li>
</ul>
<p><br></p>
<p><strong>Multiple Linear Regression in R</strong> (Adding number of cylinders and horsepower as predictors)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit a multiple linear regression model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>multiple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> cyl <span class="sc">+</span> hp <span class="sc">+</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Model summary and interpretation</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(multiple_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ cyl + hp + wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.9290 -1.5598 -0.5311  1.1850  5.8986 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 38.75179    1.78686  21.687  &lt; 2e-16 ***
cyl         -0.94162    0.55092  -1.709 0.098480 .  
hp          -0.01804    0.01188  -1.519 0.140015    
wt          -3.16697    0.74058  -4.276 0.000199 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.512 on 28 degrees of freedom
Multiple R-squared:  0.8431,    Adjusted R-squared:  0.8263 
F-statistic: 50.17 on 3 and 28 DF,  p-value: 2.184e-11</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model diagnostics (residuals vs. fitted values)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(multiple_model, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="07_week_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Model Evaluation and Comparison</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate R-squared and adjusted R-squared for both models</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>simple_r_squared <span class="ot">&lt;-</span> <span class="fu">summary</span>(simple_model)<span class="sc">$</span>r.squared</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>simple_adj_r_squared <span class="ot">&lt;-</span> <span class="fu">summary</span>(simple_model)<span class="sc">$</span>adj.r.squared</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>multiple_r_squared <span class="ot">&lt;-</span> <span class="fu">summary</span>(multiple_model)<span class="sc">$</span>r.squared</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>multiple_adj_r_squared <span class="ot">&lt;-</span> <span class="fu">summary</span>(multiple_model)<span class="sc">$</span>adj.r.squared</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare R-squared and adjusted R-squared values</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Simple Model - R-squared:"</span>, simple_r_squared, <span class="st">"Adjusted R-squared:"</span>, simple_adj_r_squared, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Simple Model - R-squared: 0.7528328 Adjusted R-squared: 0.7445939 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Multiple Model - R-squared:"</span>, multiple_r_squared, <span class="st">"Adjusted R-squared:"</span>, multiple_adj_r_squared, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multiple Model - R-squared: 0.84315 Adjusted R-squared: 0.8263446 </code></pre>
</div>
</div>
<p><strong>Model Predictions</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using the multiple linear regression model</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">cyl =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>),</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">hp =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">wt =</span> <span class="fu">c</span>(<span class="fl">2.5</span>, <span class="fl">3.0</span>, <span class="fl">3.5</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>predicted_mpg <span class="ot">&lt;-</span> <span class="fu">predict</span>(multiple_model, <span class="at">newdata =</span> new_data)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># View predicted mpg values</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>predicted_mpg</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1        2        3 
25.26408 20.89545 16.52683 </code></pre>
</div>
</div>
<p><br></p>
<p><strong>Addressing Multi-collinearity</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check for multicollinearity using the Variance Inflation Factor (VIF)</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'car' was built under R version 4.4.2</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: carData</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'car'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    recode</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:purrr':

    some</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(multiple_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     cyl       hp       wt 
4.757456 3.258481 2.580486 </code></pre>
</div>
</div>
<p><strong>Variance Inflation Factor (VIF)</strong> is a measure used to detect the presence and severity of multicollinearity in a multiple linear regression model. Multicollinearity occurs when two or more independent variables in the model are highly correlated, which can lead to instability in the estimated regression coefficients and make it difficult to interpret their individual effects on the dependent variable.</p>
<blockquote class="blockquote">
<p>If VIF values are significantly greater than 1 (&gt; 5 or 10), consider removing or combining correlated predictors</p>
</blockquote>
<p>VIF for the j-th independent variable can be calculated as:</p>
<p><span class="math display">\[
VIF(j) = \frac{1}{1 - R²(j)}
\]</span></p>
<p>Here, <span class="math inline">\(R²(j)\)</span> is the coefficient of determination (R-squared) of the regression model <u>when the j-th independent variable is regressed on all the other independent variables in the model</u>. In other words, <span class="math inline">\(R²(j)\)</span> measures the proportion of variance in the j-th independent variable that can be explained by the other independent variables.</p>
<p>If the VIF value for a particular independent variable is close to 1, it means that there is no significant multicollinearity between that variable and the other independent variables. As the VIF value increases, it suggests a higher degree of multicollinearity.</p>
<p>The general interpretation of VIF values is as follows:</p>
<ul>
<li><p>VIF = 1: No multicollinearity</p></li>
<li><p>VIF between 1 and 5: Moderate multicollinearity</p></li>
<li><p>VIF greater than 5 or 10: High multicollinearity (threshold values may vary depending on the field of study)</p></li>
</ul>
<p>If high multicollinearity is detected, it is often advisable to address the issue by removing or combining correlated predictors, or by using regularization techniques such as <em>Lasso</em>, <em>Ridge</em>, or <em>Elastic Net regression</em>. This can help improve the stability and interpretability of the regression coefficients.</p>
<p><br></p>
<p><strong>Optional:</strong> Regularization techniques (Lasso, Ridge, and Elastic Net)</p>
<p><br></p>
<p>Lasso, Ridge, and Elastic Net are <strong>regularization techniques</strong> used in linear regression models to address issues like <em>multicollinearity</em>, <em>overfitting</em>, and <em>feature selection</em>. They work by adding a penalty term to the linear regression’s objective function, which helps to shrink the coefficients towards zero and simplify the model. Here’s a brief explanation of each technique along with the relevant equations:</p>
<ol type="1">
<li><p><strong>Lasso Regression</strong> (Least Absolute Shrinkage and Selection Operator)</p>
<p>Lasso regression adds an <strong>L1</strong> penalty term to the linear regression’s objective function. The L1 penalty term is the sum of the absolute values of the coefficients. The objective function for Lasso regression is:</p>
<p><span class="math display">\[
Objective = RSS + λ Σ|β_j|
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(RSS\)</span> is the residual sum of squares.</p></li>
<li><p><span class="math inline">\(β_j\)</span> represents the j-th coefficient in the model.</p></li>
<li><p><span class="math inline">\(λ\)</span> (lambda) is the regularization parameter that controls the strength of the L1 penalty. Higher values of λ result in more shrinkage and simpler models.</p></li>
</ul>
<p>Lasso regression can drive some coefficients to zero, effectively performing feature selection by excluding irrelevant variables from the model.</p></li>
</ol>
<p><br></p>
<ol start="2" type="1">
<li><p><strong>Ridge Regression</strong></p>
<p>Ridge regression adds an <strong>L2</strong> penalty term to the linear regression’s objective function. The L2 penalty term is the sum of the squares of the coefficients. The objective function for Ridge regression is:</p>
<p><span class="math display">\[
Objective = RSS + λ  Σ(β_j)^2
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(RSS\)</span> is the residual sum of squares.</p></li>
<li><p><span class="math inline">\(β_j\)</span> represents the j-th coefficient in the model.</p></li>
<li><p><span class="math inline">\(λ\)</span> (lambda) is the regularization parameter that controls the strength of the L2 penalty. Higher values of λ result in more shrinkage and simpler models.</p></li>
</ul>
<blockquote class="blockquote">
<p><u>Ridge regression doesn’t drive coefficients to zero but can shrink them close to zero</u>, leading to a more <strong>stable</strong> and <strong>interpretable</strong> model, especially when multicollinearity is present.</p>
</blockquote></li>
</ol>
<p><br></p>
<ol start="3" type="1">
<li><p><strong>Elastic Net Regression</strong></p>
<p>Elastic Net regression combines both L1 and L2 penalty terms, effectively blending Lasso and Ridge regression (진리의 반반). The objective function for Elastic Net regression is:</p>
<p><span class="math display">\[
Objective = RSS + λ [(1 - α)  Σ(β_j)^2 + α  Σ|β_j|]
\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(RSS\)</span> is the residual sum of squares.</p></li>
<li><p><span class="math inline">\(β_j\)</span> represents the j-th coefficient in the model.</p></li>
<li><p><span class="math inline">\(λ\)</span> (lambda) is the regularization parameter that controls the overall strength of the penalty.</p></li>
<li><p><span class="math inline">\(α\)</span> (alpha) is the mixing parameter that determines the balance between L1 (Lasso) and L2 (Ridge) penalties.</p>
<ul>
<li><p>α = 1 results in Lasso regression,</p></li>
<li><p>α = 0 results in Ridge regression,</p></li>
<li><p>and values between 0 and 1 produce a mix of both.</p></li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>Elastic Net regression can be useful when there are many correlated predictors, as it can perform feature selection like Lasso while maintaining the stability and robustness of Ridge regression.</p>
</blockquote></li>
</ol>
<p><br></p>
<p>Let’s learn how to code lasso, ridge, and elastic net regression.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary library</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: Matrix</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'Matrix'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:tidyr':

    expand, pack, unpack</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loaded glmnet 4.1-8</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare data for regularization</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(mpg <span class="sc">~</span> cyl <span class="sc">+</span> hp <span class="sc">+</span> wt, <span class="at">data =</span> mtcars)[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>mpg</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit Lasso, Ridge, and Elastic Net models</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>lasso_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>ridge_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>elastic_net_model <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Cross-validation to find the optimal lambda value</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>cv_lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>cv_elastic_net <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x, y, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Model summary and interpretation</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lasso - Optimal Lambda:"</span>, cv_lasso<span class="sc">$</span>lambda.min, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Lasso - Optimal Lambda: 0.1367083 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Ridge - Optimal Lambda:"</span>, cv_ridge<span class="sc">$</span>lambda.min, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ridge - Optimal Lambda: 0.5146981 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Elastic Net - Optimal Lambda:"</span>, cv_elastic_net<span class="sc">$</span>lambda.min, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Elastic Net - Optimal Lambda: 0.1425597 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using Lasso, Ridge, and Elastic Net models:</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Create new data for predictions</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">cyl =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>),</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">hp =</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">150</span>, <span class="dv">200</span>),</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">wt =</span> <span class="fu">c</span>(<span class="fl">2.5</span>, <span class="fl">3.0</span>, <span class="fl">3.5</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare new data for predictions</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>new_data_x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> cyl <span class="sc">+</span> hp <span class="sc">+</span> wt, <span class="at">data =</span> new_data)[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>lasso_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_lasso, new_data_x, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>ridge_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_ridge, new_data_x, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>elastic_net_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv_elastic_net, new_data_x, <span class="at">s =</span> <span class="st">"lambda.min"</span>)</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="co"># View predictions</span></span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Lasso Predictions:"</span>, lasso_predictions, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Lasso Predictions: 25.13799 20.88044 16.62289 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Ridge Predictions:"</span>, ridge_predictions, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Ridge Predictions: 25.13371 20.8278 16.52189 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Elastic Net Predictions:"</span>, elastic_net_predictions, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Elastic Net Predictions: 25.18338 20.87703 16.57068 </code></pre>
</div>
</div>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>In this hands-on practice, we used the ‘mtcars’ dataset to predict miles per gallon (mpg) based on the number of cylinders, horsepower, and weight of a car. We started with a simple linear regression model using only weight as a predictor and then moved to a multiple linear regression model with three predictors. We also explored regularization techniques and made predictions using our multiple linear regression model.</p>
<p>Remember to always perform exploratory data analysis and check the assumptions of linear regression before fitting your models. Also, consider applying regularization techniques when multicollinearity is present or when the model is overfitting the data.</p>
<hr>
</section>
</section>
<section id="for-your-further-study" class="level2">
<h2 class="anchored" data-anchor-id="for-your-further-study">For your further study</h2>
<section id="derivation-of-the-coefficient-least-squares-ls-method" class="level3">
<h3 class="anchored" data-anchor-id="derivation-of-the-coefficient-least-squares-ls-method">Derivation of the Coefficient: Least Squares (LS) Method</h3>
<p>The goal of the Least Squares (LS) method is to minimize the sum of the squared differences between the observed and predicted values of the dependent variable. This method is commonly used in linear regression to estimate the coefficients <span class="math inline">\(\beta\)</span>.</p>
<p><br></p>
<section id="objective-function" class="level4">
<h4 class="anchored" data-anchor-id="objective-function">1. Objective Function</h4>
<p>We aim to minimize the following objective function:</p>
<p><span class="math display">\[
\text{Objective: } \min_{\beta} \sum_{i=1}^{n} (y_i - \hat{y_i})^2 = \min_{\beta} (y - X\beta)^T (y - X\beta)
\]</span></p>
<p>Where: - <span class="math inline">\(y\)</span> is the vector of observed dependent variable values. - <span class="math inline">\(X\)</span> is the matrix of independent variables. - <span class="math inline">\(\beta\)</span> is the vector of coefficients. - <span class="math inline">\(\hat{y_i} = X\beta\)</span> is the vector of predicted values.</p>
<p><br></p>
</section>
<section id="expanding-the-objective-function" class="level4">
<h4 class="anchored" data-anchor-id="expanding-the-objective-function">2. Expanding the Objective Function</h4>
<p>Expand the objective function:</p>
<p><span class="math display">\[
(y - X\beta)^T (y - X\beta) = y^T y - 2 \beta^T X^T y + \beta^T X^T X \beta
\]</span> <br></p>
</section>
<section id="taking-the-derivative" class="level4">
<h4 class="anchored" data-anchor-id="taking-the-derivative">3. Taking the Derivative</h4>
<p>To minimize the objective function, take the derivative with respect to <span class="math inline">\(\beta\)</span> and set it equal to 0:</p>
<p><span class="math display">\[
\frac{\partial}{\partial \beta} \left( y^T y - 2 \beta^T X^T y + \beta^T X^T X \beta \right) = 0
\]</span></p>
<p>This simplifies to:</p>
<p><span class="math display">\[
-2 X^T y + 2 X^T X \beta = 0
\]</span> <br></p>
</section>
<section id="solving-for-beta" class="level4">
<h4 class="anchored" data-anchor-id="solving-for-beta">4. Solving for beta</h4>
<p>Rearrange the equation to solve for <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
X^T X \beta = X^T y
\]</span></p>
<p><br></p>
<p>Finally, solve for <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\beta = (X^T X)^{-1} X^T y
\]</span></p>
<p><br></p>
</section>
</section>
<section id="steps-to-estimate-the-standard-error-textsehatbeta" class="level3">
<h3 class="anchored" data-anchor-id="steps-to-estimate-the-standard-error-textsehatbeta">Steps to Estimate the Standard Error <span class="math inline">\(\text{SE}(\hat{\beta})\)</span></h3>
<ol type="1">
<li><p><strong>Residual Sum of Squares (RSS)</strong>: First, compute the residuals (the difference between the observed values <span class="math inline">\(y\)</span> and the predicted values <span class="math inline">\(\hat{y} = X\hat{\beta}\)</span>) and the residual sum of squares.</p>
<p><span class="math display">\[
\text{RSS} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} \hat{\epsilon}_i^2
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(\hat{y}_i = X_i \hat{\beta}\)</span> are the predicted values.</li>
<li><span class="math inline">\(\hat{\epsilon}_i = y_i - X_i \hat{\beta}\)</span> are the residuals.</li>
</ul></li>
<li><p><strong>Estimate of Variance of Errors</strong> <span class="math inline">\(\sigma^2\)</span>: The variance of the error terms <span class="math inline">\(\sigma^2\)</span> is estimated as:</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \frac{\text{RSS}}{n - p}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(n\)</span> is the number of observations.</li>
<li><span class="math inline">\(p\)</span> is the number of parameters in the model (including the intercept).</li>
<li><span class="math inline">\(\text{RSS}\)</span> is the residual sum of squares.</li>
</ul></li>
<li><p><strong>Variance-Covariance Matrix of</strong> <span class="math inline">\(\hat{\beta}\)</span>: The variance-covariance matrix of the estimated coefficients <span class="math inline">\(\hat{\beta}\)</span> is given by:</p>
<p><span class="math display">\[
\text{Var}(\hat{\beta}) = \hat{\sigma}^2 (X^T X)^{-1}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(X\)</span> is the design matrix (the matrix of independent variables, including the intercept).</li>
<li><span class="math inline">\(X^T X\)</span> is the matrix product of <span class="math inline">\(X\)</span> transposed and <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\((X^T X)^{-1}\)</span> is the inverse of the matrix <span class="math inline">\(X^T X\)</span>.</li>
</ul></li>
<li><p><strong>Standard Error of</strong> <span class="math inline">\(\hat{\beta}\)</span>: The standard error of each coefficient <span class="math inline">\(\hat{\beta}_j\)</span> (where <span class="math inline">\(j = 1, 2, ..., p\)</span>) is the square root of the diagonal elements of the variance-covariance matrix:</p>
<p><span class="math display">\[
\text{SE}(\hat{\beta}_j) = \sqrt{\text{Var}(\hat{\beta}_j)} = \sqrt{\hat{\sigma}^2 \cdot (X^T X)^{-1}_{jj}}
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\((X^T X)^{-1}_{jj}\)</span> is the <span class="math inline">\(j\)</span>-th diagonal element of the matrix <span class="math inline">\((X^T X)^{-1}\)</span>.</li>
</ul></li>
</ol>
<p><br></p>
<p><strong>Practice in R</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some example data</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix of independent variables (X) with an intercept</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Number of observations</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">3</span>    <span class="co"># Number of predictors</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix X of independent variables with an intercept</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> (p <span class="sc">-</span> <span class="dv">1</span>)), n, p <span class="sc">-</span> <span class="dv">1</span>))  <span class="co"># X includes intercept</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a true beta (coefficients)</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fl">1.5</span>, <span class="sc">-</span><span class="dv">3</span>)  <span class="co"># True coefficients for the model</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># intercept: 2</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co"># B1: 1.5</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># B2: -3</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the dependent variable (y) with some noise</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute beta using the formula: beta = (X'X)^(-1) X'y</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1: Compute X'X (transpose of X times X)</span></span>
<span id="cb45-23"><a href="#cb45-23" aria-hidden="true" tabindex="-1"></a>XtX <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> X</span>
<span id="cb45-24"><a href="#cb45-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-25"><a href="#cb45-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2: Compute X'y (transpose of X times y)</span></span>
<span id="cb45-26"><a href="#cb45-26" aria-hidden="true" tabindex="-1"></a>Xty <span class="ot">&lt;-</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y</span>
<span id="cb45-27"><a href="#cb45-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-28"><a href="#cb45-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3: Compute the inverse of X'X</span></span>
<span id="cb45-29"><a href="#cb45-29" aria-hidden="true" tabindex="-1"></a>XtX_inv <span class="ot">&lt;-</span> <span class="fu">solve</span>(XtX)</span>
<span id="cb45-30"><a href="#cb45-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-31"><a href="#cb45-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4: Compute the estimated beta</span></span>
<span id="cb45-32"><a href="#cb45-32" aria-hidden="true" tabindex="-1"></a>beta_hat <span class="ot">&lt;-</span> XtX_inv <span class="sc">%*%</span> Xty</span>
<span id="cb45-33"><a href="#cb45-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-34"><a href="#cb45-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-35"><a href="#cb45-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-36"><a href="#cb45-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated coefficients</span></span>
<span id="cb45-37"><a href="#cb45-37" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Estimated beta coefficients:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Estimated beta coefficients:"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,]  2.135065
[2,]  1.366828
[3,] -2.976189</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the estimated beta with the true beta</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"True beta coefficients:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "True beta coefficients:"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  2.0  1.5 -3.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="do">################################################</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check how well the model fits</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>y_hat <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_hat  <span class="co"># Predicted values</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residuals</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> y <span class="sc">-</span> y_hat</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Print residual sum of squares (RSS)</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>rss <span class="ot">&lt;-</span> <span class="fu">sum</span>(residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Residual Sum of Squares (RSS):"</span>, rss))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Residual Sum of Squares (RSS): 87.7818656295526"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 5: Estimate variance of residuals (sigma^2)</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>sigma2_hat <span class="ot">&lt;-</span> rss <span class="sc">/</span> (n <span class="sc">-</span> p)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 6: Calculate standard errors of beta_hat</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>var_beta_hat <span class="ot">&lt;-</span> sigma2_hat <span class="sc">*</span> <span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>se_beta_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(var_beta_hat))</span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Using lm() to fit the model ---</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data frame to use with lm()</span></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y =</span> y, <span class="at">X1 =</span> X[, <span class="dv">2</span>], <span class="at">X2 =</span> X[, <span class="dv">3</span>])</span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the linear model using lm()</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a>model_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> X1 <span class="sc">+</span> X2, <span class="at">data =</span> df)</span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the estimated coefficients (lm())</span></span>
<span id="cb55-18"><a href="#cb55-18" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Estimated beta coefficients (lm):"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Estimated beta coefficients (lm):"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">coef</span>(model_lm))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)          X1          X2 
   2.135065    1.366828   -2.976189 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_lm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X1 + X2, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.8730 -0.6607 -0.1245  0.6214  2.0798 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.13507    0.09614   22.21   &lt;2e-16 ***
X1           1.36683    0.10487   13.03   &lt;2e-16 ***
X2          -2.97619    0.09899  -30.06   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9513 on 97 degrees of freedom
Multiple R-squared:   0.92, Adjusted R-squared:  0.9183 
F-statistic: 557.6 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><br></p>
</section>
<section id="maximum-likelihood-estimation" class="level3">
<h3 class="anchored" data-anchor-id="maximum-likelihood-estimation">Maximum Likelihood Estimation</h3>
<p>In linear regression, the method of least squares is commonly used to estimate the coefficients of the regression model. However, there is another estimation method called <strong><em>Maximum Likelihood Estimation (MLE)</em></strong> that can be used as an alternative to least squares. In this optional material, we will introduce the concept of MLE, explain how it works, and discuss its advantages and disadvantages compared to least squares.</p>
<p><br></p>
<p><strong>Maximum Likelihood Estimation</strong></p>
<blockquote class="blockquote">
<p>Maximum Likelihood Estimation is a statistical method used to estimate the parameters of a model by finding the values that maximize the likelihood function. The likelihood function measures how likely the observed data is, given the parameters of the model. In the context of linear regression, MLE seeks to find the values of the coefficients that maximize the likelihood of observing the data, assuming that the error terms follow a normal distribution</p>
</blockquote>
<p><br></p>
<p><strong>MLE in Linear Regression</strong></p>
<p>Let’s consider the linear regression model:</p>
<p><span class="math display">\[
y_i = β_0 + β_1 x_i + ε_i
\]</span></p>
<p>where <span class="math inline">\(y_i\)</span> is the dependent variable, <span class="math inline">\(x_i\)</span> is the independent variable, <span class="math inline">\(β_0\)</span> and <span class="math inline">\(β_1\)</span> are the regression coefficients, and <span class="math inline">\(ε_i\)</span> is the error term.</p>
<p>Assuming that the error terms <span class="math inline">\(ε_i\)</span> are normally distributed with mean 0 and constant variance <span class="math inline">\(σ^2\)</span>, the probability density function (<strong><em>PDF</em></strong>) of the normal distribution for a single observation is:</p>
<p><span class="math display">\[
f(y_i | x_i, β_0, β_1, σ^2) = \frac{1}{σ  \sqrt{2π}}  exp(\frac{-(y_i - (β_0 + β_1 x_i))^2}  {2  σ^2})
\]</span></p>
<p>The likelihood function is the product of the PDFs for all observations:</p>
<p><span class="math display">\[
L(β_0, β_1, σ^2) = Π f(y_i | x_i, β_0, β_1, σ^2)
\]</span></p>
<p>To make the optimization problem easier, we take the natural logarithm of the likelihood function, which is called the log-likelihood function:</p>
<p><span class="math display">\[
logL(β_0, β_1, σ^2) = Σ log(f(y_i | x_i, β_0, β_1, σ^2))
\]</span></p>
<p>The goal of MLE is to find the values of <span class="math inline">\(β_0\)</span>, <span class="math inline">\(β_1\)</span>, and <span class="math inline">\(σ^2\)</span> that maximize the log-likelihood function.</p>
<p><br></p>
<p>Practice in R</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate some example data</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># For reproducibility</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix of independent variables (X) with an intercept</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span>  <span class="co"># Number of observations</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">3</span>    <span class="co"># Number of predictors</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a matrix X of independent variables with an intercept</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="dv">1</span>, <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> (p <span class="sc">-</span> <span class="dv">1</span>)), n, p <span class="sc">-</span> <span class="dv">1</span>))  <span class="co"># X includes intercept</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a true beta (coefficients)</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="fl">1.5</span>, <span class="sc">-</span><span class="dv">3</span>)  <span class="co"># True coefficients for the model</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the dependent variable (y) with some noise</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Define the log-likelihood function for linear regression ---</span></span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>log_likelihood <span class="ot">&lt;-</span> <span class="cf">function</span>(params) {</span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>  beta <span class="ot">&lt;-</span> params[<span class="dv">1</span><span class="sc">:</span>p]  <span class="co"># Extract beta parameters</span></span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>  sigma2 <span class="ot">&lt;-</span> params[p <span class="sc">+</span> <span class="dv">1</span>]  <span class="co"># Extract variance (sigma^2)</span></span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate predicted values</span></span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a>  y_hat <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate residuals</span></span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>  residuals <span class="ot">&lt;-</span> y <span class="sc">-</span> y_hat</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Compute the log-likelihood</span></span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>  log_like <span class="ot">&lt;-</span> <span class="sc">-</span>(n <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> pi <span class="sc">*</span> sigma2) <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> sigma2)) <span class="sc">*</span> <span class="fu">sum</span>(residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>log_like)  <span class="co"># Return negative log-likelihood for minimization</span></span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Initial parameter guesses for beta and sigma^2 ---</span></span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a>init_params <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>, p), <span class="fu">var</span>(y))  <span class="co"># Initial guesses: zeros for beta, var(y) for sigma^2</span></span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Perform MLE using optim to minimize the negative log-likelihood ---</span></span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>mle_results <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> init_params, <span class="at">fn =</span> log_likelihood, <span class="at">method =</span> <span class="st">"BFGS"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced
Warning in log(2 * pi * sigma2): NaNs produced</code></pre>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract estimated betas and sigma^2</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>beta_mle <span class="ot">&lt;-</span> mle_results<span class="sc">$</span>par[<span class="dv">1</span><span class="sc">:</span>p]</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>sigma2_mle <span class="ot">&lt;-</span> mle_results<span class="sc">$</span>par[p <span class="sc">+</span> <span class="dv">1</span>]</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the results</span></span>
<span id="cb63-6"><a href="#cb63-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"Estimated beta coefficients (MLE):"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Estimated beta coefficients (MLE):"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_mle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  2.135065  1.366829 -2.976189</code></pre>
</div>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Estimated variance (sigma^2, MLE):"</span>, sigma2_mle))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Estimated variance (sigma^2, MLE): 0.877819388641911"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare the estimated betas (MLE) with the true betas</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="st">"True beta coefficients:"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "True beta coefficients:"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(beta_true)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]  2.0  1.5 -3.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check how well the model fits using MLE</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>y_hat_mle <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_mle  <span class="co"># Predicted values using MLE betas</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute residual sum of squares (RSS) for MLE</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>rss_mle <span class="ot">&lt;-</span> <span class="fu">sum</span>((y <span class="sc">-</span> y_hat_mle)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">"Residual Sum of Squares (RSS, MLE):"</span>, rss_mle))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Residual Sum of Squares (RSS, MLE): 87.7818656295527"</code></pre>
</div>
</div>
<p><br></p>
<p>The <strong><code>optim()</code></strong> function in R is a general-purpose optimization function. Its role is to find the minimum or maximum of a given objective function. In the case of MLE, we want to <strong>maximize the log-likelihood</strong> (or equivalently <strong>minimize the negative log-likelihood</strong>) to find the best estimates for our model parameters β and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>The optimization problem is often framed as <strong>minimizing</strong> some objective, so in MLE, we minimize the negative log-likelihood. The <code>optim()</code> function adjusts the parameter values to reduce the negative log-likelihood as much as possible, eventually finding the optimal estimates.</p>
<ul>
<li><p><strong><code>par = init_params</code></strong>: This argument provides the <strong>initial guesses</strong> for the parameters β and <span class="math inline">\(\sigma^2\)</span> that we are trying to estimate. In our case:</p>
<ul>
<li><p>We initialize β with zeros (or some other sensible guess).</p></li>
<li><p>We initialize <span class="math inline">\(\sigma^2\)</span> with the variance of y, since it’s a reasonable starting point for the variance of the errors.</p></li>
</ul></li>
<li><p><strong><code>fn = log_likelihood</code></strong>: This is the <strong>objective function</strong> we are trying to minimize. In our case, it’s the negative log-likelihood function (<code>log_likelihood</code>). The goal is to minimize this function by adjusting the parameters β and <span class="math inline">\(\sigma^2\)</span></p></li>
<li><p><strong><code>method = "BFGS"</code></strong>: This specifies the optimization method. <strong>BFGS</strong> stands for <strong>Broyden–Fletcher–Goldfarb–Shanno</strong> algorithm, which is a popular method used for optimization when the objective function is smooth and differentiable (as is the case here). The BFGS algorithm is well-suited for problems like this because it approximates the second derivatives of the objective function (related to curvature), making it efficient for finding local minima.</p></li>
</ul>
<section id="what-happens-inside-optim" class="level4">
<h4 class="anchored" data-anchor-id="what-happens-inside-optim">What Happens Inside <code>optim()</code>?</h4>
<p><br></p>
<ol type="1">
<li><p><strong>Initial Step</strong>:</p>
<ul>
<li>The function starts with the initial guesses for β and <span class="math inline">\(\sigma^2\)</span> provided in <code>init_params</code>.</li>
</ul></li>
<li><p><strong>Evaluate the Objective Function</strong>:</p>
<ul>
<li><p><code>optim()</code> calculates the <strong>negative log-likelihood</strong> for the current parameter values using the <code>log_likelihood()</code> function.</p></li>
<li><p>It evaluates how far off the current guess is by computing the residuals <span class="math inline">\(y - X\beta\)</span> and using those residuals to calculate the likelihood.</p></li>
</ul></li>
<li><p><strong>Iterative Optimization</strong>:</p>
<ul>
<li><p><code>optim()</code> adjusts the parameter values iteratively. It evaluates the <strong>gradient</strong> (the direction in which the objective function decreases most quickly) and <strong>step size</strong> (how far to move in the direction of the gradient).</p></li>
<li><p>With each iteration, the algorithm updates β and <span class="math inline">\(\sigma^2\)</span> slightly and recalculates the negative log-likelihood.</p></li>
<li><p>This process continues until the algorithm finds a set of parameters where the negative log-likelihood is minimized (i.e., the most likely parameters given the data).</p></li>
</ul></li>
<li><p><strong>Convergence</strong>:</p>
<ul>
<li><p>Once the negative log-likelihood cannot be significantly reduced by adjusting the parameters (i.e., when it has “converged” to a solution), <code>optim()</code> stops.</p></li>
<li><p>At this point, the current values of β and <span class="math inline">\(\sigma^2\)</span> are considered the <strong>Maximum Likelihood Estimates (MLEs)</strong>.</p></li>
</ul></li>
</ol>
</section>
<section id="the-log-likelihood-function-whats-being-minimized" class="level4">
<h4 class="anchored" data-anchor-id="the-log-likelihood-function-whats-being-minimized">The Log-Likelihood Function: What’s Being Minimized?</h4>
<p>The <strong>log-likelihood function</strong> describes the probability of observing the data given the parameters <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>. For a linear regression model with normally distributed errors, the log-likelihood is:</p>
<p><span class="math display">\[
\mathcal{L}(\beta, \sigma^2 | X, y) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i - X_i \beta)^2
\]</span></p>
<p>Our goal is to <strong>maximize</strong> this function. Since <code>optim()</code> minimizes functions by default, we instead minimize the <strong>negative log-likelihood</strong>:</p>
<p><span class="math display">\[
-\mathcal{L}(\beta, \sigma^2 | X, y) = \frac{n}{2} \log(2\pi\sigma^2) + \frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i - X_i \beta)^2
\]</span></p>
<p>The negative log-likelihood consists of two parts:</p>
<ol type="1">
<li>The first part, <span class="math inline">\(\frac{n}{2} \log(2\pi\sigma^2)\)</span>, depends on the variance <span class="math inline">\(\sigma^2\)</span>.</li>
<li>The second part, <span class="math inline">\(\frac{1}{2\sigma^2} \sum_{i=1}^{n} (y_i - X_i \beta)^2\)</span>, depends on the residuals (differences between observed and predicted values) and both <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>.</li>
</ol>
<p>The <strong>optimizer</strong> (<code>optim()</code>) will adjust the values of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> to minimize this expression, thereby maximizing the likelihood of the data given the model parameters.</p>
<p><br></p>
<p><strong>Advantages and Disadvantages of MLE</strong></p>
<p>Advantages:</p>
<ul>
<li><p>MLE provides a general framework that can be applied to a wide range of statistical models, not just linear regression.</p></li>
<li><p>MLE is asymptotically unbiased and efficient, meaning that as the sample size increases, the estimates converge to the true parameter values, and the estimates have the smallest possible variance.</p></li>
<li><p>MLE allows for the estimation of additional parameters, such as the error variance <span class="math inline">\(σ^2\)</span> in linear regression.</p></li>
</ul>
<p>Disadvantages:</p>
<ul>
<li><p>MLE can be computationally intensive, especially for complex models with many parameters.</p></li>
<li><p>MLE relies on the assumption that the error terms follow a specific distribution (e.g., normal distribution in linear regression). If this assumption is not met, the estimates may be biased or inefficient.</p></li>
</ul>
<p>Let’s demonstrate the similarity of the estimates by fitting a linear regression model using both LS and MLE, and then visualize the fitted lines. To do this, we’ll predict miles per gallon (mpg) based on the weight (wt) of a car using the ‘mtcars’ dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'MASS'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    select</code></pre>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the 'mtcars' dataset</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Fit the linear regression model using LS (lm function):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using LS</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>ls_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(mpg <span class="sc">~</span> wt, <span class="at">data =</span> mtcars)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ls_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ wt, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5432 -2.3647 -0.1252  1.4096  6.8727 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
wt           -5.3445     0.5591  -9.559 1.29e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.046 on 30 degrees of freedom
Multiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 
F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
</div>
</div>
<p>Fit the linear regression model using MLE (fit a normal linear model with mle2 function):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load necessary libraries</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bbmle)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: stats4</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'bbmle'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:dplyr':

    slice</code></pre>
</div>
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-likelihood function for MLE</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>loglik_fn <span class="ot">&lt;-</span> <span class="cf">function</span>(beta0, beta1, sigma) {</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>mpg</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> mtcars<span class="sc">$</span>wt</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> beta0 <span class="sc">+</span> beta1 <span class="sc">*</span> x</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>  epsilon <span class="ot">&lt;-</span> y <span class="sc">-</span> mu</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>  loglik <span class="ot">&lt;-</span> <span class="sc">-</span>n<span class="sc">/</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">2</span> <span class="sc">*</span> pi) <span class="sc">-</span> n<span class="sc">/</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(sigma<span class="sc">^</span><span class="dv">2</span>) <span class="sc">-</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">2</span> <span class="sc">*</span> sigma<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> <span class="fu">sum</span>(epsilon<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span>loglik) <span class="co"># The optimization function will minimize the function, so we need to negate the log-likelihood</span></span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model using MLE</span></span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>mle_model <span class="ot">&lt;-</span> <span class="fu">mle2</span>(loglik_fn, <span class="at">start =</span> <span class="fu">list</span>(<span class="at">beta0 =</span> <span class="fu">coef</span>(ls_model)[<span class="dv">1</span>], </span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">beta1 =</span> <span class="fu">coef</span>(ls_model)[<span class="dv">2</span>], </span>
<span id="cb85-18"><a href="#cb85-18" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">sigma =</span> <span class="dv">1</span>))</span>
<span id="cb85-19"><a href="#cb85-19" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mle_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Maximum likelihood estimation

Call:
mle2(minuslogl = loglik_fn, start = list(beta0 = coef(ls_model)[1], 
    beta1 = coef(ls_model)[2], sigma = 1))

Coefficients:
      Estimate Std. Error z value     Pr(z)    
beta0 37.28513    1.81800 20.5088 &lt; 2.2e-16 ***
beta1 -5.34447    0.54135 -9.8725 &lt; 2.2e-16 ***
sigma  2.94916    0.36864  8.0000 1.244e-15 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

-2 log L: 160.0294 </code></pre>
</div>
</div>
<p>Visualize the fitted lines:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients from the LS and MLE models</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>ls_coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(ls_model)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>mle_coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(mle_model)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a scatter plot of mpg vs. wt</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>mtcars_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(mtcars, <span class="fu">aes</span>(<span class="at">x =</span> wt, <span class="at">y =</span> mpg)) <span class="sc">+</span></span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">5.5</span>)) <span class="sc">+</span></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">40</span>))</span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Add the LS and MLE fitted lines to the plot</span></span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>mtcars_plot <span class="sc">+</span></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">intercept =</span> ls_coefs[<span class="dv">1</span>], <span class="at">slope =</span> ls_coefs[<span class="dv">2</span>], <span class="at">color =</span> <span class="st">"LS"</span>, <span class="at">linetype =</span> <span class="st">"LS"</span>), <span class="at">size =</span> <span class="dv">1</span>, <span class="at">alpha=</span><span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">intercept =</span> mle_coefs[<span class="dv">1</span>], <span class="at">slope =</span> mle_coefs[<span class="dv">2</span>], <span class="at">color =</span> <span class="st">"MLE"</span>, <span class="at">linetype =</span> <span class="st">"MLE"</span>), <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="st">"Model"</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"LS"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"MLE"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_linetype_manual</span>(<span class="st">"Model"</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"LS"</span> <span class="ot">=</span> <span class="st">"solid"</span>, <span class="st">"MLE"</span> <span class="ot">=</span> <span class="st">"dashed"</span>)) <span class="sc">+</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Linear Regression: LS vs. MLE"</span>, <span class="at">x =</span> <span class="st">"Weight"</span>, <span class="at">y =</span> <span class="st">"Miles per Gallon"</span>) <span class="sc">+</span></span>
<span id="cb87-18"><a href="#cb87-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="07_week_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>In the resulting plot, you’ll notice that the LS and MLE fitted lines are almost indistinguishable, which confirms that the estimates are the same when the error terms follow a normal distribution.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>License: <a href="https://creativecommons.org/licenses/by-sa/2.0/">CC BY-SA 2.0</a>.</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ChangjunChrisLee/">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Dr_CJLee">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>