---
title: "Review & Wrap-up"
subtitle: "수업 리뷰" 
Week: 14
format: html
slide-format: revealjs
---

[Weekly content](https://changjunlee.com/teaching/grad_stat/weekly_2/)

<br>

## Structural Equation Modeling: Foundations and Applications

<br>

### **Introduction**

Structural Equation Modeling (SEM) is **a comprehensive statistical methodology that combines factor analysis and multiple regression techniques to examine complex relationships among observed and latent variables**. Over the past few decades, SEM has become a powerful tool for researchers across disciplines such as social sciences, psychology, education, business, and health sciences. This chapter introduces the theoretical underpinnings of SEM, its key components, and practical applications, with an emphasis on latent variables and path analysis.

<bR>

### **Key Concepts in SEM**

#### **1. Observed and Latent Variables**

-   **Observed Variables**: These are directly measured variables, often referred to as indicators. For example, responses to survey items like "I enjoy learning" and "I find studying rewarding" can serve as observed variables for the latent construct "Motivation."

-   **Latent Variables**: These are unobserved constructs that are inferred from observed variables. SEM excels in estimating latent variables while accounting for measurement error.

#### **2. Measurement Error**

Measurement error is the discrepancy between the observed value and the true value of a variable. SEM explicitly incorporates measurement error into its models, which sets it apart from traditional regression approaches.

![](images/clipboard-167134754.png)

#### **3. Path Diagrams**

Path diagrams visually represent SEM models. Key components include:

-   **Circles**: Represent latent variables.

-   **Squares**: Represent observed variables.

-   **Arrows**: Depict causal relationships or associations.

<br>

### **Components of SEM**

#### **1. Measurement Model**

The measurement model specifies the relationships between latent variables and their observed indicators. It answers the question: [*How well do the observed variables measure the underlying construct?*]{.underline}

**Example**: Motivation as a latent variable might be measured by three observed items:

$$
Motivation \sim Item_1 + Item_2 + Item_3
$$

​<br>

#### **2. Structural Model**

The structural model specifies the relationships between latent variables (or between latent and observed variables). It answers the question: *What are the causal relationships between constructs?*

**Example**: Testing whether motivation mediates the relationship between hours studied and test performance:

$$
Test\_Score = Motivation + Hours\_Studied
$$

$$
Motivation = Hours\_Studied
$$

<br>

### **Steps in Conducting SEM**

#### **Step 1: Define the Model**

Develop a theoretical model based on prior research or hypotheses. Clearly specify the relationships among variables in a path diagram.

#### **Step 2: Specify the Model**

Translate the path diagram into a set of equations. This involves defining the measurement and structural models.

#### **Step 3: Collect Data**

Ensure the dataset includes sufficient sample size and all observed indicators for latent variables.

#### **Step 4: Estimate the Model**

Use software such as R (`lavaan` package), AMOS, Mplus, or LISREL to estimate the parameters.

#### **Step 5: Evaluate Model Fit**

Examine fit indices and modify the model, if necessary, based on theoretical justifications.

#### **Step 6: Interpret the Results**

Interpret path coefficients, factor loadings, and fit indices in the context of your research question.

<Br>

## **Cronbach's Alpha: A Measure of Reliability**

#### **Introduction**

Cronbach's Alpha (α) is a widely used statistic in research to assess the **internal consistency reliability** of a set of items or indicators. It is particularly useful for measuring the reliability of scales, tests, or questionnaires in social sciences, psychology, education, and other fields. Reliability refers to the extent to which a scale produces consistent results across repeated measurements or multiple items measuring the same construct.

### **Conceptual Foundation**

#### **Internal Consistency**

Internal consistency evaluates how well the items in a scale measure the same underlying construct. If items are highly correlated, it suggests they are measuring the same concept, which contributes to higher reliability.

For example:

-   A scale measuring **motivation** might include items like:

    -   "I enjoy learning new things."

    -   "I am motivated to achieve my goals."

    -   "I find studying rewarding."

If these items are highly interrelated, the scale has good internal consistency.

#### **Definition of Cronbach's Alpha**

Cronbach's Alpha quantifies internal consistency as a value between 0 and 1. Higher values indicate better reliability. The formula for α is:

$$
\alpha = \frac{k}{k - 1} \left(1 - \frac{\sum s_i^2}{s_t^2}\right)
$$

Where:

-   k: Number of items in the scale.

    -   문항 수가 많을 수록 신뢰도를 과소평가하는 경향이 있어 이를 보정

-   $s_i^2$​: Variance of each individual item.

    -   개별 문항 분산의 합: 개별 문항들이 얼마나 **독립적**으로 변동하는지

-   $s_t^2$​: Variance of the total scale score.

    -   총합 점수의 분산으로, 문항ndefined들이 **함께 변동**하는 정도

    -   비율: 각 문항이 개별적으로 변동하는 정도를 전체 점수의 변동과 비교

        -   비율의 값이 클 수록 문항들이 서로 독립적으로 작동, 내적 일관성이 낮아짐

        -   값이 작을 수록 문항들이 함께 움직이며, 내적 일관성이 높아짐

        -   1에서 이 비율을 뺌으로써 문항들이 공통으로 기여하는 정도를 측정

<br>

### **Interpreting Cronbach's Alpha**

-   α \> 0.90: Excellent reliability (possibly redundant items).

-   0.80 ≤ α \< 0.90: Good reliability.

-   0.70 ≤ α \< 0.80: Acceptable reliability.

-   0.60 ≤ α \< 0.70: Questionable reliability.

-   α \< 0.60: Poor reliability (likely indicates issues with item quality or scale design).

<Br>

### **Assumptions of Cronbach's Alpha**

1.  **Unidimensionality**: The scale should measure a single construct.

2.  **Equal Variance Contribution**: Each item should contribute equally to the total score (violations can lead to under- or overestimation of reliability).

3.  **Correlation Between Items**: Items should be positively correlated.

<Br>

### **Practical Example: Calculating Cronbach's Alpha in R**

#### **Simulating a Dataset**

```{r}
# Simulate data for a 5-item motivation scale
set.seed(123)
n <- 100  # Number of respondents
motivation_data <- data.frame(
  Q1 = rnorm(n, mean = 4, sd = 0.8),  # Item 1
  Q2 = rnorm(n, mean = 4.2, sd = 0.7),  # Item 2
  Q3 = rnorm(n, mean = 3.9, sd = 0.9),  # Item 3
  Q4 = rnorm(n, mean = 4.1, sd = 0.6),  # Item 4
  Q5 = rnorm(n, mean = 4.0, sd = 0.8)   # Item 5
)
head(motivation_data, 10)

```

```{r}
# Install and load the psych package
# install.packages("psych")
library(psych)

# Calculate Cronbach's Alpha
alpha_result <- psych::alpha(motivation_data)
print(alpha_result)

```

#### **Output Interpretation**

The output includes:

-   **Raw Alpha**: The Cronbach's Alpha for the current scale.

    -   **raw_alpha (-0.38)**

        -   음수의 알파 값은 **내적 일관성이 전혀 없거나, 문항들이 서로 부정적인 관계를 가질 가능성**을 나타냄

        -   문항들이 측정하려는 동일한 개념(동일 구성 개념)을 반영하지 않거나, 측정 대상이 전혀 다른 경우에 나타남

-   **Standardized Alpha**: Adjusted for standardized item variances.

-   **Item-Total Correlations**: Correlation of each item with the total scale score.

-   **Alpha If Deleted**: The α value if a specific item is removed.

<br>

### **Improving Reliability**

1.  **Increase the Number of Items**: Add more items that measure the same construct.

2.  **Refine Items**: Ensure items are clear, relevant, and unambiguous.

3.  **Remove Low-Quality Items**: Exclude items that weaken the overall reliability (α).

<br>

## **Confirmatory Factor Analysis (CFA)**

### **Introduction**

Confirmatory Factor Analysis (CFA) is **a statistical technique used to test whether a hypothesized measurement model fits the observed data**. Unlike Exploratory Factor Analysis (EFA), which identifies underlying factor structures without prior assumptions, CFA is **hypothesis-driven** and requires the researcher to specify the relationships between observed variables and latent factors before analysis.

CFA is widely used in psychology, education, and social sciences to validate measurement scales, confirm theoretical constructs, and ensure the reliability of instruments.

<br>

### **Key Concepts in CFA**

#### **1. Latent Variables**

Latent variables are unobserved constructs that are inferred from multiple observed variables. For example:

-   **Motivation** might be a latent variable inferred from survey items like "I enjoy studying" and "I set academic goals."

#### **2. Observed Variables (Indicators)**

These are measurable variables that serve as proxies for the latent variable. In CFA, each observed variable is expected to load on a specific latent factor.

#### **3. Factor Loadings**

Factor loadings quantify the relationship between observed variables and their underlying latent factor. Higher loadings indicate stronger relationships.

#### **4. Measurement Errors**

CFA explicitly models measurement error for each observed variable, improving the accuracy of parameter estimates compared to traditional methods.

<br>

### **The CFA Model**

The CFA model is typically represented as:

$$
X = \Lambda \xi + \delta
$$

Where:

-   X: Vector of observed variables.

-   Λ: Matrix of factor loadings.

-   ξ: Vector of latent variables.

-   δ: Vector of measurement errors.

<bR>

### **Model Fit Indices in CFA**

Several indices are used to assess the goodness of fit of a CFA model:

1.  **Chi-Square**:

    -   Tests the [null hypothesis that the model fits the data perfectly.]{.underline}

    -   Smaller, non-significant values indicate a good fit.

    -   Sensitive to sample size.

2.  **CFI (Comparative Fit Index)**:

    -   Compares the fit of the hypothesized model to a null model.

    -   Values \> 0.90 indicate good fit; \> 0.95 indicates excellent fit.

3.  **TLI (Tucker-Lewis Index)**:

    -   Adjusts for model complexity.

    -   Values \> 0.90 indicate good fit.

4.  **RMSEA (Root Mean Square Error of Approximation)**:

    -   Measures the discrepancy between the model and the data per degree of freedom.

    -   Values \< 0.08 indicate acceptable fit; \< 0.05 indicates excellent fit.

5.  **SRMR (Standardized Root Mean Square Residual)**:

    -   Measures the average discrepancy between observed and predicted correlations.

    -   Values \< 0.08 indicate a good fit.

<br>

### **Example of CFA in R**

Here, we validate a hypothetical 3-factor model with 9 observed variables.

#### **Simulating the Data**

```{r}
# Simulate data for a 3-factor model
set.seed(123)
n <- 300

# Latent variables
Factor1 <- rnorm(n, mean = 5, sd = 1)
Factor2 <- rnorm(n, mean = 3, sd = 1)
Factor3 <- rnorm(n, mean = 4, sd = 1)

# Observed variables
Item1 <- 0.8 * Factor1 + rnorm(n, sd = 0.5)
Item2 <- 0.7 * Factor1 + rnorm(n, sd = 0.5)
Item3 <- 0.9 * Factor1 + rnorm(n, sd = 0.5)

Item4 <- 0.8 * Factor2 + rnorm(n, sd = 0.5)
Item5 <- 0.7 * Factor2 + rnorm(n, sd = 0.5)
Item6 <- 0.9 * Factor2 + rnorm(n, sd = 0.5)

Item7 <- 0.8 * Factor3 + rnorm(n, sd = 0.5)
Item8 <- 0.7 * Factor3 + rnorm(n, sd = 0.5)
Item9 <- 0.9 * Factor3 + rnorm(n, sd = 0.5)

data <- data.frame(Item1, Item2, Item3, Item4, Item5, Item6, Item7, Item8, Item9)

head(data, 10)
```

Defining and Running the CFA Model

```{r}
# Load lavaan package
library(lavaan)

# Define the CFA model
model <- '
  Factor1 =~ Item1 + Item2 + Item3
  Factor2 =~ Item4 + Item5 + Item6
  Factor3 =~ Item7 + Item8 + Item9
'

# Fit the model
fit <- cfa(model, data = data)

# Summary with standardized estimates
summary(fit, fit.measures = TRUE, standardized = TRUE)

```

#### **Output**

#### (1) **Chi-square 테스트**

-   **Test statistic = 16.404, Degrees of freedom = 24, P-value = 0.873**

    -   높은 p값(0.873)은 귀무가설(H0)을 기각하지 않음을 나타냄.

    -   **귀무가설:** "모형이 데이터와 잘 맞는다" → p \> 0.05이므로, 데이터가 모형에 잘 적합한다고 해석할 수 있음.

#### (2) **Comparative Fit Index (CFI)와 Tucker-Lewis Index (TLI)**

-   **CFI = 1.000, TLI = 1.008**

    -   CFI와 TLI 값이 0.95 이상이면 적합성이 매우 우수하다고 판단.

    -   여기서는 두 지표 모두 매우 높은 값(1 이상)을 보여, 모델 적합성이 뛰어나다는 것을 보임.

#### (3) **Root Mean Square Error of Approximation (RMSEA)**

-   **RMSEA = 0.000, 90% CI = \[0.000, 0.024\], P-value = 0.998**

    -   RMSEA 값이 0.05 이하이고, 90% 신뢰구간의 상한선도 0.05 이하라면 적합성이 우수하다고 볼 수 있음.

    -   P-value H0: RMSEA ≤ 0.050 = 0.998 → "RMSEA가 0.05 이하"라는 귀무가설을 채택.

    -   RMSEA가 0에 가까워 매우 좋은 적합도를 나타냄.

#### (4) **Standardized Root Mean Square Residual (SRMR)**

-   **SRMR = 0.021**

    -   SRMR 값이 0.08 이하라면 적합성이 양호하다고 판단.

#### (5) **요인 적재값(Factor Loadings)**

-   각 항목이 요인에 대해 얼마나 강하게 연관되어 있는지

    -   **Factor1:**

        -   Item1: 0.805 (표준화된 적재값 0.877)

        -   Item2: 0.596 (표준화된 적재값 0.772)

        -   Item3: 0.793 (표준화된 적재값 0.834)

    -   **Factor2:**

        -   Item4: 0.768 (표준화된 적재값 0.835)

        -   Item5: 0.662 (표준화된 적재값 0.807)

        -   Item6: 0.924 (표준화된 적재값 0.898)

    -   **Factor3:**

        -   Item7: 0.786 (표준화된 적재값 0.845)

        -   Item8: 0.647 (표준화된 적재값 0.772)

        -   Item9: 0.969 (표준화된 적재값 0.903)

-   표준화 적재값이 **0.7 이상**이면 해당 항목이 요인에 강하게 기여한다고 판단.

#### (6) **요인 간 공분산(Covariances)** 

-   Factor1 \~\~ Factor2 = -0.033 (p = 0.615)

-   Factor1 \~\~ Factor3 = -0.015 (p = 0.820)

-   Factor2 \~\~ Factor3 = -0.027 (p = 0.680)

    -   요인 간 공분산이 매우 낮고 통계적으로 유의하지 않음.

    -   요인들이 서로 독립적(서로 다른 구성 개념을 측정)을 나타냄.

#### **(7) 항목의 잔차(Residual Variances)**

-   각 항목의 분산 중 설명되지 않는 부분(잔차)

    -   Item1: 잔차 분산 = 0.194 (설명되지 않는 분산 비율 = 23.1%)

    -   Item6: 잔차 분산 = 0.204 (설명되지 않는 분산 비율 = 19.3%)

    -   대부분의 항목에서 설명되지 않는 분산 비율이 적어(50% 미만), 요인이 해당 항목들을 잘 설명하고 있음을 나타냄.

<br>

## SEM Practice

```{r}
# Install lavaan if not already installed
# install.packages("lavaan")

# Load lavaan
library(lavaan)

```

```{r}
# Load required package for data simulation
library(MASS)

# Set random seed for reproducibility
set.seed(123)

# Number of observations
n <- 300

# Define factor structure (3 latent factors, uncorrelated)
latent_factors <- mvrnorm(
  n = n,
  mu = c(0, 0, 0),       # Mean of latent factors
  Sigma = diag(3)        # Identity matrix implies no correlation between factors
)

# Factor loadings for each latent factor
loadings <- list(
  Factor1 = c(0.8, 0.7, 0.9),  # Loadings for Item1, Item2, Item3
  Factor2 = c(0.9, 0.8, 0.85), # Loadings for Item4, Item5, Item6
  Factor3 = c(0.85, 0.75, 0.9) # Loadings for Item7, Item8, Item9
)

# Residual variances (to ensure observed variables are not perfectly predicted by latent factors)
residuals <- list(
  Factor1 = c(0.4, 0.5, 0.3),
  Factor2 = c(0.3, 0.4, 0.35),
  Factor3 = c(0.35, 0.5, 0.3)
)

# Generate observed variables for each factor
observed_data <- data.frame(
  Item1 = latent_factors[, 1] * loadings$Factor1[1] + rnorm(n, 0, residuals$Factor1[1]),
  Item2 = latent_factors[, 1] * loadings$Factor1[2] + rnorm(n, 0, residuals$Factor1[2]),
  Item3 = latent_factors[, 1] * loadings$Factor1[3] + rnorm(n, 0, residuals$Factor1[3]),
  Item4 = latent_factors[, 2] * loadings$Factor2[1] + rnorm(n, 0, residuals$Factor2[1]),
  Item5 = latent_factors[, 2] * loadings$Factor2[2] + rnorm(n, 0, residuals$Factor2[2]),
  Item6 = latent_factors[, 2] * loadings$Factor2[3] + rnorm(n, 0, residuals$Factor2[3]),
  Item7 = latent_factors[, 3] * loadings$Factor3[1] + rnorm(n, 0, residuals$Factor3[1]),
  Item8 = latent_factors[, 3] * loadings$Factor3[2] + rnorm(n, 0, residuals$Factor3[2]),
  Item9 = latent_factors[, 3] * loadings$Factor3[3] + rnorm(n, 0, residuals$Factor3[3])
)

# Check summary
summary(observed_data)

```

-   CFA first

```{r}
# Load lavaan package for SEM
library(lavaan)

# Define the CFA model
cfa_model <- '
  # Latent variables
  Factor1 =~ Item1 + Item2 + Item3
  Factor2 =~ Item4 + Item5 + Item6
  Factor3 =~ Item7 + Item8 + Item9

  # Covariances (optional; default assumes correlated factors)
  Factor1 ~~ Factor2
  Factor1 ~~ Factor3
  Factor2 ~~ Factor3
'

# Fit the CFA model
cfa_fit <- cfa(model = cfa_model, data = observed_data)

# Summarize results
summary(cfa_fit, fit.measures = TRUE, standardized = TRUE)

# Check model fit indices
fitMeasures(cfa_fit)

# Inspect modification indices (to identify potential model improvements)
modificationIndices(cfa_fit, sort = TRUE)

# Residuals analysis
residuals(cfa_fit, type = "cor")

# Visualize the model (optional)
# install.packages("semPlot")
library(semPlot)
semPaths(cfa_fit, what = "std", layout = "tree", 
         nCharNodes = 0, edge.label.cex = 0.8)

```

-   **적합도 지표 (Fit Indices):**

    -   좋은 적합도 기준:

        -   **CFI, TLI ≥ 0.95**

        -   **RMSEA ≤ 0.05**

        -   **SRMR ≤ 0.08**

-   **표준화 요인 적재값 (Standardized Factor Loadings):**

    -   각 항목이 대응하는 잠재변수에 대해 얼마나 강하게 기여하는지

    -   기준: 적재값 ≥ 0.7이면 "강한 기여"로 해석.

-   **수정지수 (Modification Indices):**

    -   모델 개선 가능성이 높은 항목 간의 경로를 제안합니다. 수정이 필요한 경우 수정 후 재분석 가능.

-   **잔차 (Residuals):**

    -   관찰된 값과 모델로 예측된 값 간의 차이를 분석합니다. 잔차가 작을수록 모델이 데이터를 잘 설명.

```{r}
# Standardized loadings table
inspect(cfa_fit, what = "std")

# Covariance matrix of latent factors
inspect(cfa_fit, what = "cov.lv")

```

<br>

#### Fitting to SEM

```{r}
# SEM 모델 정의
sem_model <- '
  # Measurement model (측정 모델: 요인 구조 정의)
  Factor1 =~ Item1 + Item2 + Item3
  Factor2 =~ Item4 + Item5 + Item6
  Factor3 =~ Item7 + Item8 + Item9

  # Structural model (구조 모델: 요인 간 관계 정의)
  Factor2 ~ Factor1  # Factor1이 Factor2에 영향을 미침
  Factor3 ~ Factor2  # Factor2가 Factor3에 영향을 미침
  Factor3 ~ Factor1 + Factor2 #매개효과
'

```

```{r}
# SEM 모델 적합
sem_fit <- sem(model = sem_model, data = observed_data)

# 결과 요약
summary(sem_fit, fit.measures = TRUE, standardized = TRUE)

# 적합도 지표 확인
fitMeasures(sem_fit)

# 수정지수 확인 (필요시 모델 수정)
modificationIndices(sem_fit, sort = TRUE)

```

```{r}
# semPaths() 함수 수정: 경로의 투명도 및 색상 조정
semPaths(
  object = sem_fit,         # SEM 모델 객체
  what = "std",             # 표준화된 경로 계수 표시
  layout = "tree",          # 트리 레이아웃
  edge.label.cex = 1.2,     # 경로 레이블 크기 (더 크게)
  edge.color = "black",     # 선 색상 지정
  edge.width = 1,         # 선의 두께
  residuals = TRUE,         # 잔차 포함
  intercepts = FALSE,       # 절편 제거
  fade = FALSE,             # 투명도 조정 (FALSE로 설정하여 선을 더 선명하게)
  nCharNodes = 0            # 노드 이름의 길이 제한 없음
)

```
